{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0871e+06: 100%|██████████| 5000/5000 [24:58<00:00,  3.14it/s]\n",
      "Finished [100%]: Average Loss = 2.0867e+06\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0812 11:19:48.185542 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0867e+06\n",
      "100%|██████████| 500/500 [00:05<00:00, 84.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@5000@500:0.9804182162728664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.083e+06: 100%|██████████| 5000/5000 [24:45<00:00,  3.44it/s] \n",
      "Finished [100%]: Average Loss = 2.0828e+06\n",
      "I0812 11:45:29.598526 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0828e+06\n",
      "100%|██████████| 1000/1000 [00:10<00:00, 95.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@5000@1000:0.9854684948379328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0882e+06: 100%|██████████| 5000/5000 [25:09<00:00,  3.47it/s]\n",
      "Finished [100%]: Average Loss = 2.0879e+06\n",
      "I0812 12:12:18.099126 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0879e+06\n",
      "100%|██████████| 2000/2000 [00:20<00:00, 105.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@5000@2000:0.9836454746536717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0845e+06: 100%|██████████| 5000/5000 [24:32<00:00,  3.26it/s]\n",
      "Finished [100%]: Average Loss = 2.0842e+06\n",
      "I0812 12:40:08.105290 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0842e+06\n",
      "100%|██████████| 3000/3000 [00:31<00:00, 96.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@5000@3000:0.980841957952647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0862e+06: 100%|██████████| 5000/5000 [33:58<00:00,  3.21it/s]  \n",
      "Finished [100%]: Average Loss = 2.0859e+06\n",
      "I0812 13:19:06.926990 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0859e+06\n",
      "100%|██████████| 4000/4000 [00:43<00:00, 91.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@5000@4000:0.9794085931419838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0877e+06: 100%|██████████| 5000/5000 [24:35<00:00,  3.64it/s]\n",
      "Finished [100%]: Average Loss = 2.0872e+06\n",
      "I0812 13:59:47.859596 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0872e+06\n",
      "100%|██████████| 5000/5000 [00:50<00:00, 99.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@5000@5000:0.9784143295536037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0134e+06: 100%|██████████| 10000/10000 [48:36<00:00,  3.44it/s]\n",
      "Finished [100%]: Average Loss = 2.0134e+06\n",
      "I0812 15:02:32.818759 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0134e+06\n",
      "100%|██████████| 500/500 [00:05<00:00, 104.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@10000@500:0.9555768143437289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0122e+06: 100%|██████████| 10000/10000 [48:55<00:00,  3.34it/s]\n",
      "Finished [100%]: Average Loss = 2.0121e+06\n",
      "I0812 15:52:19.026696 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0121e+06\n",
      "100%|██████████| 1000/1000 [00:10<00:00, 98.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@10000@1000:0.9533534134599794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0123e+06: 100%|██████████| 10000/10000 [50:22<00:00,  3.27it/s]\n",
      "Finished [100%]: Average Loss = 2.0123e+06\n",
      "I0812 16:44:21.573227 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0123e+06\n",
      "100%|██████████| 2000/2000 [00:23<00:00, 84.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@10000@2000:0.9510986672277515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0116e+06: 100%|██████████| 10000/10000 [53:19<00:00,  2.76it/s] \n",
      "Finished [100%]: Average Loss = 2.0115e+06\n",
      "I0812 17:41:16.513270 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0115e+06\n",
      "100%|██████████| 3000/3000 [00:33<00:00, 89.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@10000@3000:0.9499134214956941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0129e+06: 100%|██████████| 10000/10000 [50:48<00:00,  3.47it/s] \n",
      "Finished [100%]: Average Loss = 2.0129e+06\n",
      "I0812 18:37:14.592741 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0129e+06\n",
      "100%|██████████| 4000/4000 [00:39<00:00, 101.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@10000@4000:0.950581257901429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.0126e+06: 100%|██████████| 10000/10000 [49:47<00:00,  3.48it/s]\n",
      "Finished [100%]: Average Loss = 2.0125e+06\n",
      "I0812 19:38:37.369939 140151031424768 inference.py:248] Finished [100%]: Average Loss = 2.0125e+06\n",
      "100%|██████████| 5000/5000 [00:50<00:00, 98.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@10000@5000:0.9492662444564417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.9979e+06: 100%|██████████| 15000/15000 [1:14:41<00:00,  3.46it/s]\n",
      "Finished [100%]: Average Loss = 1.9979e+06\n",
      "I0812 21:46:49.510546 140151031424768 inference.py:248] Finished [100%]: Average Loss = 1.9979e+06\n",
      "100%|██████████| 500/500 [00:04<00:00, 108.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@15000@500:0.956140938088188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.9977e+06: 100%|██████████| 15000/15000 [1:13:12<00:00,  3.56it/s]\n",
      "Finished [100%]: Average Loss = 1.9977e+06\n",
      "I0812 23:00:54.097531 140151031424768 inference.py:248] Finished [100%]: Average Loss = 1.9977e+06\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 100.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@15000@1000:0.9541811267022896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.9981e+06: 100%|██████████| 15000/15000 [1:13:39<00:00,  3.56it/s]\n",
      "Finished [100%]: Average Loss = 1.9981e+06\n",
      "I0813 00:16:12.508225 140151031424768 inference.py:248] Finished [100%]: Average Loss = 1.9981e+06\n",
      "100%|██████████| 2000/2000 [00:19<00:00, 104.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@15000@2000:0.9504516403890475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.998e+06: 100%|██████████| 15000/15000 [1:13:28<00:00,  3.33it/s] \n",
      "Finished [100%]: Average Loss = 1.998e+06\n",
      "I0813 01:32:54.783015 140151031424768 inference.py:248] Finished [100%]: Average Loss = 1.998e+06\n",
      "100%|██████████| 3000/3000 [00:32<00:00, 92.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@15000@3000:0.9506565058638523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.998e+06: 100%|██████████| 15000/15000 [1:16:01<00:00,  3.03it/s] \n",
      "Finished [100%]: Average Loss = 1.998e+06\n",
      "I0813 02:54:14.088793 140151031424768 inference.py:248] Finished [100%]: Average Loss = 1.998e+06\n",
      "100%|██████████| 4000/4000 [00:38<00:00, 102.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@15000@4000:0.9512104394888395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.998e+06: 100%|██████████| 15000/15000 [1:30:09<00:00,  2.58it/s] \n",
      "Finished [100%]: Average Loss = 1.998e+06\n",
      "I0813 04:46:58.082096 140151031424768 inference.py:248] Finished [100%]: Average Loss = 1.998e+06\n",
      "100%|██████████| 5000/5000 [00:59<00:00, 84.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@15000@5000:0.9514533182685636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.9948e+06: 100%|██████████| 20000/20000 [1:49:48<00:00,  3.12it/s]\n",
      "Finished [100%]: Average Loss = 1.9948e+06\n",
      "I0813 06:45:39.624917 140151031424768 inference.py:248] Finished [100%]: Average Loss = 1.9948e+06\n",
      "100%|██████████| 500/500 [00:08<00:00, 62.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@20000@500:0.9544583928512111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.1501e+06:  19%|█▊        | 3725/20000 [20:29<1:39:52,  2.72it/s]"
     ]
    }
   ],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.08.12\n",
    "@function: BMFBias(Bayesian Matrix Factorization with bias) \n",
    "           Datatset: MovieLens-1m:https://grouplens.org/datasets/movielens/  \n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import heapq\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.train.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        maxu, maxi, maxr = data['user'].max()+1, data['item'].max()+1, data['rating'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.test.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "    \n",
    "    def list_to_dict(self, dataset):\n",
    "        dataDict = {}\n",
    "        for u,i,r in dataset:\n",
    "            dataDict[int(u), int(i)] = float(r)\n",
    "        return dataDict\n",
    "    \n",
    "    def getInstances(self, dataset):\n",
    "        user = []\n",
    "        item = []\n",
    "        rate = []\n",
    "        for u, i, r in dataset:\n",
    "            user.append(int(u))\n",
    "            item.append(int(i))\n",
    "            rate.append(float(r))\n",
    "        return np.array(user), np.array(item), np.array(rate)\n",
    "    \n",
    "class BMF():\n",
    "    def __init__(self, ds):\n",
    "        self.maxr = ds.maxr\n",
    "        self.maxu = ds.maxu\n",
    "        self.maxi = ds.maxi\n",
    "        #get the trainset and testset\n",
    "        train_u, train_i, train_r = ds.getInstances(ds.trainset)\n",
    "        shuffled_idx = np.random.permutation(np.arange(len(train_u)))\n",
    "        self.train_u = train_u[shuffled_idx]\n",
    "        self.train_i = train_i[shuffled_idx]\n",
    "        self.train_r = train_r[shuffled_idx]\n",
    "        assert(len(self.train_u) == len(self.train_i) and len(self.train_i) == len(self.train_r)) \n",
    "        self.test_u, self.test_i, self.test_r = ds.getInstances(ds.testset)\n",
    "        assert(len(self.test_u) == len(self.test_i) and len(self.test_i) == len(self.test_r))\n",
    "    \n",
    "    def train_BMF(self, K=8, step=5000, spl=500):\n",
    "        self.x_u = theano.shared(self.train_u)\n",
    "        self.x_i = theano.shared(self.train_i)\n",
    "        self.y_r = theano.shared(self.train_r)\n",
    "        with pm.Model() as self.bmf:#bulid probabilistic model\n",
    "            meanr = self.maxr/2\n",
    "            # Creating the model\n",
    "            P = pm.Normal('P', mu=0, sd=meanr, shape=(self.maxu, K))\n",
    "            Q = pm.Normal('Q', mu=0, sd=meanr, shape=(self.maxi, K))\n",
    "            #bias\n",
    "            b_u = pm.Normal('b_u', mu=0, sd=meanr, shape=self.maxu)\n",
    "            b_i = pm.Normal('b_i', mu=0, sd=meanr, shape=self.maxi)\n",
    "            u = pm.Normal('u', mu=0, sd=meanr)\n",
    "            tY = pm.Deterministic('tY', tt.add(tt.add(tt.add(b_u[self.x_u],b_i[self.x_i]),tt.sum(P[self.x_u,:]*Q[self.x_i,:], axis=1)),u))\n",
    "            #likelihood function\n",
    "            Y = pm.Normal('Y', mu=tY, sd=meanr, observed=self.y_r)\n",
    "            \n",
    "        with self.bmf: #train the probabilistic model by Bayesian inference\n",
    "            tstart = time.time()\n",
    "            logging.info('Start training BMF')\n",
    "            approx = pm.fit(n=step, method=pm.ADVI())\n",
    "            trace = approx.sample(draws=spl)\n",
    "            elapsed = time.time() - tstart \n",
    "            logging.info('Complete BMF training in %d seconds' % int(elapsed))\n",
    "        return trace\n",
    "            \n",
    "    def eval_BMF(self, trace):\n",
    "        self.x_u.set_value(self.test_u)\n",
    "        self.x_i.set_value(self.test_i)\n",
    "        self.y_r.set_value(self.test_r)\n",
    "        with self.bmf:\n",
    "            ppc = pm.sample_posterior_predictive(trace, progressbar=True)\n",
    "            pY = ppc['Y'].mean(axis=0)\n",
    "        assert(pY.shape[0]==self.test_r.shape[0])\n",
    "        squaredError = []\n",
    "        for i in range(pY.shape[0]):\n",
    "            error=self.test_r[i] - pY[i]\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        return rmse\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\n",
    "    bmf = BMF(ds)#negative sample ratio\n",
    "    for step in [5000, 10000, 15000]:#\n",
    "        for spl in [500, 1000, 2000, 3000, 4000, 5000]:\n",
    "            trace = bmf.train_BMF(K=8, step=step, spl=spl)\n",
    "            rmse = bmf.eval_BMF(trace)\n",
    "            print(\"RMSE@{}@{}:{}\".format(step,spl,rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 2313189, User = 10216, Item = 96324, Sparsity = 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 7.0614e+06: 100%|██████████| 10000/10000 [4:38:47<00:00,  1.60s/it] \n",
      "Finished [100%]: Average Loss = 7.0607e+06\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0811 04:27:39.656300 140377736296192 inference.py:248] Finished [100%]: Average Loss = 7.0607e+06\n",
      "100%|██████████| 500/500 [00:05<00:00, 95.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@16:1.3327729249836142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 8.0402e+06: 100%|██████████| 10000/10000 [9:31:11<00:00,  3.36s/it]  \n",
      "Finished [100%]: Average Loss = 8.0388e+06\n",
      "I0811 14:03:40.021590 140377736296192 inference.py:248] Finished [100%]: Average Loss = 8.0388e+06\n",
      "100%|██████████| 500/500 [00:06<00:00, 77.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@32:1.3463370430432309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.4368e+07:  29%|██▊       | 2861/10000 [9:13:00<14:24:07,  7.26s/it] "
     ]
    }
   ],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.08.10\n",
    "@function: BMFBias(Bayesian Matrix Factorization with bias) \n",
    "           Datatset: KnowledgeBase-CC\n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import heapq\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/kbcc_trainset.csv\" \n",
    "        data = pd.read_csv(filePath, sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "        maxu, maxi, maxr = data['csr'].max()+1, data['ke'].max()+1, data['num'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/kbcc_testset.csv\" \n",
    "        data = pd.read_csv(filePath, sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "    \n",
    "    def list_to_dict(self, dataset):\n",
    "        dataDict = {}\n",
    "        for u,i,r in dataset:\n",
    "            dataDict[int(u), int(i)] = float(r)\n",
    "        return dataDict\n",
    "    \n",
    "    def getInstances(self, dataset):\n",
    "        user = []\n",
    "        item = []\n",
    "        rate = []\n",
    "        for u, i, r in dataset:\n",
    "            user.append(int(u))\n",
    "            item.append(int(i))\n",
    "            rate.append(float(r))\n",
    "        return np.array(user), np.array(item), np.array(rate)\n",
    "    \n",
    "class BMF():\n",
    "    def __init__(self, ds):\n",
    "        self.maxr = ds.maxr\n",
    "        self.maxu = ds.maxu\n",
    "        self.maxi = ds.maxi\n",
    "        #get the trainset and testset\n",
    "        train_u, train_i, train_r = ds.getInstances(ds.trainset)\n",
    "        shuffled_idx = np.random.permutation(np.arange(len(train_u)))\n",
    "        self.train_u = train_u[shuffled_idx]\n",
    "        self.train_i = train_i[shuffled_idx]\n",
    "        self.train_r = train_r[shuffled_idx]\n",
    "        assert(len(self.train_u) == len(self.train_i) and len(self.train_i) == len(self.train_r)) \n",
    "        self.test_u, self.test_i, self.test_r = ds.getInstances(ds.testset)\n",
    "        assert(len(self.test_u) == len(self.test_i) and len(self.test_i) == len(self.test_r))\n",
    "    \n",
    "    def train_BMF(self, K=8):\n",
    "        self.x_u = theano.shared(self.train_u)\n",
    "        self.x_i = theano.shared(self.train_i)\n",
    "        self.y_r = theano.shared(self.train_r)\n",
    "        with pm.Model() as self.bmf:#bulid probabilistic model\n",
    "            meanr = self.maxr/2\n",
    "            # Creating the model\n",
    "            P = pm.Normal('P', mu=0, sd=meanr, shape=(self.maxu, K))\n",
    "            Q = pm.Normal('Q', mu=0, sd=meanr, shape=(self.maxi, K))\n",
    "            #bias\n",
    "            b_u = pm.Normal('b_u', mu=0, sd=meanr, shape=self.maxu)\n",
    "            b_i = pm.Normal('b_i', mu=0, sd=meanr, shape=self.maxi)\n",
    "            u = pm.Normal('u', mu=0, sd=meanr)\n",
    "            tY = pm.Deterministic('tY', tt.add(tt.add(tt.add(b_u[self.x_u],b_i[self.x_i]),tt.sum(P[self.x_u,:]*Q[self.x_i,:], axis=1)),u))\n",
    "            #likelihood function\n",
    "            Y = pm.Normal('Y', mu=tY, sd=meanr, observed=self.y_r)\n",
    "            \n",
    "        with self.bmf: #train the probabilistic model by Bayesian inference\n",
    "            tstart = time.time()\n",
    "            logging.info('Start training BMF')\n",
    "            approx = pm.fit(n=10000, method=pm.ADVI())\n",
    "            trace = approx.sample(draws=500)\n",
    "            elapsed = time.time() - tstart \n",
    "            logging.info('Complete BMF training in %d seconds' % int(elapsed))\n",
    "        return trace\n",
    "            \n",
    "    def eval_BMF(self, trace):\n",
    "        self.x_u.set_value(self.test_u)\n",
    "        self.x_i.set_value(self.test_i)\n",
    "        self.y_r.set_value(self.test_r)\n",
    "        with self.bmf:\n",
    "            ppc = pm.sample_posterior_predictive(trace, progressbar=True)\n",
    "            pY = ppc['Y'].mean(axis=0)\n",
    "        assert(pY.shape[0]==self.test_r.shape[0])\n",
    "        squaredError = []\n",
    "        for i in range(pY.shape[0]):\n",
    "            error=self.test_r[i] - pY[i]\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        return rmse\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\n",
    "    bmf = BMF(ds)#negative sample ratio\n",
    "    for K in [16, 32, 64]:#8, \n",
    "        trace = bmf.train_BMF(K)\n",
    "        rmse = bmf.eval_BMF(trace)\n",
    "        print(\"RMSE@{}:{}\".format(K, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.5768e+06: 100%|██████████| 20000/20000 [12:39:36<00:00,  2.08s/it]  \n",
      "Finished [100%]: Average Loss = 2.5767e+06\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0803 13:33:45.902980 140106723780352 inference.py:248] Finished [100%]: Average Loss = 2.5767e+06\n",
      "100%|██████████| 2000/2000 [00:33<00:00, 59.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@64:0.9552209868260392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.08.01\n",
    "@function: BMFBias(Bayesian Matrix Factorization with bias) \n",
    "           Datatset: MovieLens-1m:https://grouplens.org/datasets/movielens/  \n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import heapq\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.train.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        maxu, maxi, maxr = data['user'].max()+1, data['item'].max()+1, data['rating'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.test.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "    \n",
    "    def list_to_dict(self, dataset):\n",
    "        dataDict = {}\n",
    "        for u,i,r in dataset:\n",
    "            dataDict[int(u), int(i)] = float(r)\n",
    "        return dataDict\n",
    "    \n",
    "    def getInstances(self, dataset):\n",
    "        user = []\n",
    "        item = []\n",
    "        rate = []\n",
    "        for u, i, r in dataset:\n",
    "            user.append(int(u))\n",
    "            item.append(int(i))\n",
    "            rate.append(float(r))\n",
    "        return np.array(user), np.array(item), np.array(rate)\n",
    "    \n",
    "class BMF():\n",
    "    def __init__(self, ds):\n",
    "        self.maxr = ds.maxr\n",
    "        self.maxu = ds.maxu\n",
    "        self.maxi = ds.maxi\n",
    "        #get the trainset and testset\n",
    "        train_u, train_i, train_r = ds.getInstances(ds.trainset)\n",
    "        shuffled_idx = np.random.permutation(np.arange(len(train_u)))\n",
    "        self.train_u = train_u[shuffled_idx]\n",
    "        self.train_i = train_i[shuffled_idx]\n",
    "        self.train_r = train_r[shuffled_idx]\n",
    "        assert(len(self.train_u) == len(self.train_i) and len(self.train_i) == len(self.train_r)) \n",
    "        self.test_u, self.test_i, self.test_r = ds.getInstances(ds.testset)\n",
    "        assert(len(self.test_u) == len(self.test_i) and len(self.test_i) == len(self.test_r))\n",
    "    \n",
    "    def train_BMF(self, K=8):\n",
    "        self.x_u = theano.shared(self.train_u)\n",
    "        self.x_i = theano.shared(self.train_i)\n",
    "        self.y_r = theano.shared(self.train_r)\n",
    "        with pm.Model() as self.bmf:#bulid probabilistic model\n",
    "            meanr = self.maxr/2\n",
    "            # Creating the model\n",
    "            P = pm.Normal('P', mu=0, sd=meanr, shape=(self.maxu, K))\n",
    "            Q = pm.Normal('Q', mu=0, sd=meanr, shape=(self.maxi, K))\n",
    "            #bias\n",
    "            b_u = pm.Normal('b_u', mu=0, sd=meanr, shape=self.maxu)\n",
    "            b_i = pm.Normal('b_i', mu=0, sd=meanr, shape=self.maxi)\n",
    "            u = pm.Normal('u', mu=0, sd=meanr)\n",
    "            tY = pm.Deterministic('tY', tt.add(tt.add(tt.add(b_u[self.x_u],b_i[self.x_i]),tt.sum(P[self.x_u,:]*Q[self.x_i,:], axis=1)),u))\n",
    "            #likelihood function\n",
    "            Y = pm.Normal('Y', mu=tY, sd=meanr, observed=self.y_r)\n",
    "            \n",
    "        with self.bmf: #train the probabilistic model by Bayesian inference\n",
    "            tstart = time.time()\n",
    "            logging.info('Start training BMF')\n",
    "            approx = pm.fit(n=20000, method=pm.ADVI())\n",
    "            trace = approx.sample(draws=2000)\n",
    "            elapsed = time.time() - tstart \n",
    "            logging.info('Complete BMF training in %d seconds' % int(elapsed))\n",
    "        return trace\n",
    "            \n",
    "    def eval_BMF(self, trace):\n",
    "        self.x_u.set_value(self.test_u)\n",
    "        self.x_i.set_value(self.test_i)\n",
    "        self.y_r.set_value(self.test_r)\n",
    "        with self.bmf:\n",
    "            ppc = pm.sample_posterior_predictive(trace, progressbar=True)\n",
    "            pY = ppc['Y'].mean(axis=0)\n",
    "        assert(pY.shape[0]==self.test_r.shape[0])\n",
    "        squaredError = []\n",
    "        for i in range(pY.shape[0]):\n",
    "            error=self.test_r[i] - pY[i]\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        return rmse\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\n",
    "    bmf = BMF(ds)#negative sample ratio\n",
    "    for K in [8, 16, 32]:#64\n",
    "        trace = bmf.train_BMF(K)\n",
    "        rmse = bmf.eval_BMF(trace)\n",
    "        print(\"RMSE@{}:{}\".format(K, rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 0.0444\n",
      "Complete one epoch training in 222 seconds\n",
      "RMSE@8:3.795998241438821\n",
      "Complete one epoch training in 236 seconds\n",
      "RMSE@16:3.795998241438821\n",
      "Complete one epoch training in 322 seconds\n",
      "RMSE@32:3.795998241438821\n",
      "Complete one epoch training in 4881 seconds\n",
      "RMSE@64:3.795998241438821\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.08.12\n",
    "@function: baseline: BPMF(Bayesian Probabilistic Matrix Factorization)\n",
    "           paper: https://dl.acm.org/citation.cfm?id=1390267\n",
    "           Datatset: MovieLens-1m:https://grouplens.org/datasets/movielens/  \n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.stats import wishart\n",
    "import time\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.train.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        maxu, maxi, maxr = data['user'].max()+1, data['item'].max()+1, data['rating'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.test.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "    \n",
    "def Normal_Wishart(mu_0, lamb, W, nu, seed=None):\n",
    "    \"\"\"Function extracting a Normal_Wishart random variable\"\"\"\n",
    "    # first draw a Wishart distribution:\n",
    "    Lambda = wishart(df=nu, scale=W, seed=seed).rvs()  # NB: Lambda is a matrix.\n",
    "    # then draw a Gaussian multivariate RV with mean mu_0 and(lambda*Lambda)^{-1} as covariance matrix.\n",
    "    cov = np.linalg.inv(lamb * Lambda)  # this is the bottleneck!!\n",
    "    mu = multivariate_normal(mu_0, cov)\n",
    "    return mu, Lambda, cov\n",
    "\n",
    "def BPMF(R, R_test, U_in, V_in, T, D, initial_cutoff, lowest_rating, highest_rating,\n",
    "         mu_0=None, Beta_0=None, W_0=None, nu_0=None):\n",
    "    \"\"\"\n",
    "    R is the ranking matrix (NxM, N=#users, M=#movies); we are assuming that R[i,j]=0 means that user i has not ranked movie j\n",
    "    R_test is the ranking matrix that contains test values. Same assumption as above. \n",
    "    U_in, V_in are the initial values for the MCMC procedure. \n",
    "    T is the number of steps. \n",
    "    D is the number of hidden features that are assumed in the model.    \n",
    "    \n",
    "    mu_0 is the average vector used in sampling the multivariate normal variable\n",
    "    Beta_0 is a coefficient (?)\n",
    "    W_0 is the DxD scale matrix in the Wishart sampling \n",
    "    nu_0 is the number of degrees of freedom used in the Wishart sampling. \n",
    "    \n",
    "    U matrices are DxN, while V matrices are DxM.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def ranked(i, j):  # function telling if user i ranked movie j in the train dataset.\n",
    "        if R[i, j] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def ranked_test(i, j):  # function telling if user i ranked movie j in the test dataset.\n",
    "        if R_test[i, j] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    N = R.shape[0]\n",
    "    M = R.shape[1]\n",
    "\n",
    "    R_predict = np.zeros((N, M))\n",
    "    U_old = np.array(U_in)\n",
    "    V_old = np.array(V_in)\n",
    "\n",
    "    # initialize now the hierarchical priors:\n",
    "    alpha = 2  # observation noise, they put it = 2 in the paper\n",
    "    mu_u = np.zeros((D, 1))\n",
    "    mu_v = np.zeros((D, 1))\n",
    "    Lambda_U = np.eye(D)\n",
    "    Lambda_V = np.eye(D)\n",
    "\n",
    "    # COUNT HOW MAY PAIRS ARE IN THE TEST AND TRAIN SET:\n",
    "    pairs_test = 0\n",
    "    pairs_train = 0\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            if ranked(i, j):\n",
    "                pairs_train = pairs_train + 1\n",
    "            if ranked_test(i, j):\n",
    "                pairs_test = pairs_test + 1\n",
    "\n",
    "    # print(pairs_test, pairs_train)\n",
    "\n",
    "    # SET THE DEFAULT VALUES for Wishart distribution\n",
    "    # we assume that parameters for both U and V are the same.\n",
    "\n",
    "    if mu_0 is None:\n",
    "        mu_0 = np.zeros(D)\n",
    "    if nu_0 is None:\n",
    "        nu_0 = D\n",
    "    if Beta_0 is None:\n",
    "        Beta_0 = 2\n",
    "    if W_0 is None:\n",
    "        W_0 = np.eye(D)\n",
    "        \n",
    "    # results = pd.DataFrame(columns=['step', 'train_err', 'test_err'])\n",
    "\n",
    "    for t in range(T):\n",
    "        # print(\"Step \", t)\n",
    "        # FIRST SAMPLE THE HYPERPARAMETERS, conditioned on the present step user and movie feature matrices U_t and V_t:\n",
    "\n",
    "        # parameters common to both distributions:\n",
    "        Beta_0_star = Beta_0 + N\n",
    "        nu_0_star = nu_0 + N\n",
    "        W_0_inv = np.linalg.inv(W_0)  # compute the inverse once and for all\n",
    "\n",
    "        # movie hyperparameters:\n",
    "        V_average = np.sum(V_old, axis=1) / N  # in this way it is a 1d array!!\n",
    "        # print (V_average.shape)\n",
    "        S_bar_V = np.dot(V_old, np.transpose(V_old)) / N  # CHECK IF THIS IS RIGHT!\n",
    "        mu_0_star_V = (Beta_0 * mu_0 + N * V_average) / (Beta_0 + N)\n",
    "        W_0_star_V_inv = W_0_inv + N * S_bar_V + Beta_0 * N / (Beta_0 + N) * np.dot(\n",
    "            np.transpose(np.array(mu_0 - V_average, ndmin=2)), np.array((mu_0 - V_average), ndmin=2))\n",
    "        W_0_star_V = np.linalg.inv(W_0_star_V_inv)\n",
    "        mu_V, Lambda_V, cov_V = Normal_Wishart(mu_0_star_V, Beta_0_star, W_0_star_V, nu_0_star, seed=None)\n",
    "\n",
    "        # user hyperparameters\n",
    "        # U_average=np.transpose(np.array(np.sum(U_old, axis=1)/N, ndmin=2)) #the np.array and np.transpose are needed for it to be a column vector\n",
    "        U_average = np.sum(U_old, axis=1) / N  # in this way it is a 1d array!!  #D-long\n",
    "        # print (U_average.shape)\n",
    "        S_bar_U = np.dot(U_old, np.transpose(U_old)) / N  # CHECK IF THIS IS RIGHT! #it is DxD\n",
    "        mu_0_star_U = (Beta_0 * mu_0 + N * U_average) / (Beta_0 + N)\n",
    "        W_0_star_U_inv = W_0_inv + N * S_bar_U + Beta_0 * N / (Beta_0 + N) * np.dot(\n",
    "            np.transpose(np.array(mu_0 - U_average, ndmin=2)), np.array((mu_0 - U_average), ndmin=2))\n",
    "        W_0_star_U = np.linalg.inv(W_0_star_U_inv)\n",
    "        mu_U, Lambda_U, cov_U = Normal_Wishart(mu_0_star_U, Beta_0_star, W_0_star_U, nu_0_star, seed=None)\n",
    "\n",
    "        # print (S_bar_U.shape, S_bar_V.shape)\n",
    "        # print (np.dot(np.transpose(np.array(mu_0-U_average, ndmin=2)),np.array((mu_0-U_average), ndmin=2).shape))\n",
    "\n",
    "        # UP TO HERE IT PROBABLY WORKS, FROM HERE ON IT HAS TO BE CHECKED!!!\n",
    "\n",
    "        \"\"\"SAMPLE THEN USER FEATURES (possibly in parallel):\"\"\"\n",
    "\n",
    "        U_new = np.array([])  # define the new stuff.\n",
    "        V_new = np.array([])\n",
    "\n",
    "        for i in range(N):  # loop over the users\n",
    "            # first compute the parameters of the distribution\n",
    "            Lambda_U_2 = np.zeros((D, D))  # second term in the construction of Lambda_U\n",
    "            mu_i_star_1 = np.zeros(D)  # first piece of mu_i_star\n",
    "            for j in range(M):  # loop over the movies\n",
    "                if ranked(i, j):  # only if movie j has been ranked by user i!\n",
    "                    Lambda_U_2 = Lambda_U_2 + np.dot(np.transpose(np.array(V_old[:, j], ndmin=2)),\n",
    "                                                     np.array((V_old[:, j]), ndmin=2))  # CHECK\n",
    "                    mu_i_star_1 = V_old[:, j] * R[i, j] + mu_i_star_1  # CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "                    # coeff=np.transpose(np.array(V_old[j]*R[i,j], ndmin=2))+coeff  #CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "\n",
    "            Lambda_i_star_U = Lambda_U + alpha * Lambda_U_2\n",
    "            Lambda_i_star_U_inv = np.linalg.inv(Lambda_i_star_U)\n",
    "\n",
    "            mu_i_star_part = alpha * mu_i_star_1 + np.dot(Lambda_U,\n",
    "                                                          mu_U)  ###CAREFUL!! Multiplication matrix times a row vector!! It should give as an output a row vector as for how it works\n",
    "            mu_i_star = np.dot(Lambda_i_star_U_inv, mu_i_star_part)\n",
    "            # extract now the U values!\n",
    "            U_new = np.append(U_new, multivariate_normal(mu_i_star, Lambda_i_star_U_inv))\n",
    "\n",
    "        # you need to reshape U_new and transpose it!!\n",
    "        U_new = np.transpose(np.reshape(U_new, (N, D)))\n",
    "        # print (U_new.shape)\n",
    "\n",
    "        \"\"\"SAMPLE THEN MOVIE FEATURES (possibly in parallel):\"\"\"\n",
    "\n",
    "        for j in range(M):\n",
    "            Lambda_V_2 = np.zeros((D, D))  # second term in the construction of Lambda_U\n",
    "            mu_i_star_1 = np.zeros(D)  # first piece of mu_i_star\n",
    "            for i in range(N):  # loop over the movies\n",
    "                if ranked(i, j):\n",
    "                    Lambda_V_2 = Lambda_V_2 + np.dot(np.transpose(np.array(U_new[:, i], ndmin=2)),\n",
    "                                                     np.array((U_new[:, i]), ndmin=2))\n",
    "                    mu_i_star_1 = U_new[:, i] * R[i, j] + mu_i_star_1  # CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "                    # coeff=np.transpose(np.array(V_old[j]*R[i,j], ndmin=2))+coeff  #CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "\n",
    "            Lambda_j_star_V = Lambda_V + alpha * Lambda_V_2\n",
    "            Lambda_j_star_V_inv = np.linalg.inv(Lambda_j_star_V)\n",
    "\n",
    "            mu_i_star_part = alpha * mu_i_star_1 + np.dot(Lambda_V, mu_V)\n",
    "            mu_j_star = np.dot(Lambda_j_star_V_inv, mu_i_star_part)\n",
    "            V_new = np.append(V_new, multivariate_normal(mu_j_star, Lambda_j_star_V_inv))\n",
    "\n",
    "        # you need to reshape U_new and transpose it!!\n",
    "        V_new = np.transpose(np.reshape(V_new, (M, D)))\n",
    "\n",
    "        # save U_new and V_new in U_old and V_old for next iteration:         \n",
    "        U_old = np.array(U_new)\n",
    "        V_old = np.array(V_new)\n",
    "\n",
    "        if t > initial_cutoff:  # initial_cutoff is needed to discard the initial transient\n",
    "            R_step = np.dot(np.transpose(U_new), V_new)\n",
    "            for i in range(N):  # reduce all the predictions to the correct ratings range.\n",
    "                for j in range(M):\n",
    "                    if R_step[i, j] > highest_rating:\n",
    "                        R_step[i, j] = highest_rating\n",
    "                    elif R_step[i, j] < lowest_rating:\n",
    "                        R_step[i, j] = lowest_rating\n",
    "\n",
    "            R_predict = (R_predict * (t - initial_cutoff - 1) + R_step) / (t - initial_cutoff)\n",
    "            \n",
    "            '''\n",
    "            train_err_list = []\n",
    "            train_err = 0  # initialize the errors.\n",
    "            # compute now the RMSE on the train dataset:\n",
    "            for i in range(N):\n",
    "                for j in range(M):\n",
    "                    if ranked(i, j):\n",
    "                        train_err = train_err + (R_predict[i, j] - R[i, j]) ** 2\n",
    "            train_err_list.append(np.sqrt(train_err / pairs_train))\n",
    "            print(\"Training RMSE at iteration \", t - initial_cutoff, \" :   \", \"{:.4}\".format(train_err_list[-1]))\n",
    "            '''\n",
    "            # compute now the RMSE on the test dataset:\n",
    "            test_err = 0\n",
    "            test_err_list = []\n",
    "            for i in range(N):\n",
    "                for j in range(M):\n",
    "                    if ranked_test(i, j):\n",
    "                        test_err = test_err + (R_predict[i, j] - R_test[i, j]) ** 2\n",
    "            test_err_list.append(np.sqrt(test_err / pairs_test))\n",
    "            print(\"Test RMSE at iteration \", t - initial_cutoff, \" :   \", \"{:.8}\".format(test_err_list[-1]))\n",
    "            \n",
    "    return R_predict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\\\n",
    "    R = ds.list_to_matrix(ds.trainset, ds.maxu, ds.maxi)#get matrix\n",
    "    R_test = ds.list_to_matrix(ds.testset, ds.maxu, ds.maxi)#get matrix\n",
    "    for K in [8, 16, 32, 64]: \n",
    "        tstart = time.time()\n",
    "        U_in = np.zeros((K, ds.maxu))  \n",
    "        V_in = np.zeros((K, ds.maxi))\n",
    "        nR = BPMF(R, R_test, U_in, V_in, T=1, D=K, initial_cutoff=0, lowest_rating=0, highest_rating=ds.maxr)\n",
    "        elapsed = time.time() - tstart \n",
    "        print('Complete one epoch training in %d seconds' % int(elapsed))\n",
    "        squaredError = []\n",
    "        for u,i,r in ds.testset:\n",
    "            error=r - nR[int(u)][int(i)]\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        print(\"RMSE@{}:{}\".format(K, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 2313189, User = 10216, Item = 96324, Sparsity = 0.0024\n",
      "Test RMSE at iteration  1  :    1.3086415\n",
      "Test RMSE at iteration  2  :    1.3075052\n",
      "Test RMSE at iteration  3  :    1.1931455\n",
      "Test RMSE at iteration  4  :    0.94657374\n",
      "Test RMSE at iteration  5  :    0.86203469\n",
      "Test RMSE at iteration  6  :    0.87539859\n",
      "Test RMSE at iteration  7  :    0.93389999\n",
      "Test RMSE at iteration  8  :    1.0112213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:202: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE at iteration  9  :    1.0898997\n",
      "RMSE@16:1.0898997379726185\n",
      "Test RMSE at iteration  1  :    1.3083713\n",
      "Test RMSE at iteration  2  :    1.3069004\n",
      "Test RMSE at iteration  3  :    1.1865972\n",
      "Test RMSE at iteration  4  :    0.94585557\n",
      "Test RMSE at iteration  5  :    0.86714039\n",
      "Test RMSE at iteration  6  :    0.88678609\n",
      "Test RMSE at iteration  7  :    0.95800129\n",
      "Test RMSE at iteration  8  :    1.0552011\n",
      "Test RMSE at iteration  9  :    1.1560709\n",
      "RMSE@32:1.1560708701853317\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.08.09\n",
    "@function: baseline: BPMF(Bayesian Probabilistic Matrix Factorization)\n",
    "           paper: https://dl.acm.org/citation.cfm?id=1390267\n",
    "           Datatset: KnowledgeBase-CC \n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.stats import wishart\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/kbcc_trainset.csv\" \n",
    "        data = pd.read_csv(filePath, sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "        maxu, maxi, maxr = data['csr'].max()+1, data['ke'].max()+1, data['num'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/kbcc_testset.csv\" \n",
    "        data = pd.read_csv(filePath, sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "    \n",
    "def Normal_Wishart(mu_0, lamb, W, nu, seed=None):\n",
    "    \"\"\"Function extracting a Normal_Wishart random variable\"\"\"\n",
    "    # first draw a Wishart distribution:\n",
    "    Lambda = wishart(df=nu, scale=W, seed=seed).rvs()  # NB: Lambda is a matrix.\n",
    "    # then draw a Gaussian multivariate RV with mean mu_0 and(lambda*Lambda)^{-1} as covariance matrix.\n",
    "    cov = np.linalg.inv(lamb * Lambda)  # this is the bottleneck!!\n",
    "    mu = multivariate_normal(mu_0, cov)\n",
    "    return mu, Lambda, cov\n",
    "\n",
    "def BPMF(R, R_test, U_in, V_in, T, D, initial_cutoff, lowest_rating, highest_rating,\n",
    "         mu_0=None, Beta_0=None, W_0=None, nu_0=None):\n",
    "    \"\"\"\n",
    "    R is the ranking matrix (NxM, N=#users, M=#movies); we are assuming that R[i,j]=0 means that user i has not ranked movie j\n",
    "    R_test is the ranking matrix that contains test values. Same assumption as above. \n",
    "    U_in, V_in are the initial values for the MCMC procedure. \n",
    "    T is the number of steps. \n",
    "    D is the number of hidden features that are assumed in the model.    \n",
    "    \n",
    "    mu_0 is the average vector used in sampling the multivariate normal variable\n",
    "    Beta_0 is a coefficient (?)\n",
    "    W_0 is the DxD scale matrix in the Wishart sampling \n",
    "    nu_0 is the number of degrees of freedom used in the Wishart sampling. \n",
    "    \n",
    "    U matrices are DxN, while V matrices are DxM.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def ranked(i, j):  # function telling if user i ranked movie j in the train dataset.\n",
    "        if R[i, j] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def ranked_test(i, j):  # function telling if user i ranked movie j in the test dataset.\n",
    "        if R_test[i, j] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    N = R.shape[0]\n",
    "    M = R.shape[1]\n",
    "\n",
    "    R_predict = np.zeros((N, M))\n",
    "    U_old = np.array(U_in)\n",
    "    V_old = np.array(V_in)\n",
    "\n",
    "    # initialize now the hierarchical priors:\n",
    "    alpha = 2  # observation noise, they put it = 2 in the paper\n",
    "    mu_u = np.zeros((D, 1))\n",
    "    mu_v = np.zeros((D, 1))\n",
    "    Lambda_U = np.eye(D)\n",
    "    Lambda_V = np.eye(D)\n",
    "\n",
    "    # COUNT HOW MAY PAIRS ARE IN THE TEST AND TRAIN SET:\n",
    "    pairs_test = 0\n",
    "    pairs_train = 0\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            if ranked(i, j):\n",
    "                pairs_train = pairs_train + 1\n",
    "            if ranked_test(i, j):\n",
    "                pairs_test = pairs_test + 1\n",
    "\n",
    "    # print(pairs_test, pairs_train)\n",
    "\n",
    "    # SET THE DEFAULT VALUES for Wishart distribution\n",
    "    # we assume that parameters for both U and V are the same.\n",
    "\n",
    "    if mu_0 is None:\n",
    "        mu_0 = np.zeros(D)\n",
    "    if nu_0 is None:\n",
    "        nu_0 = D\n",
    "    if Beta_0 is None:\n",
    "        Beta_0 = 2\n",
    "    if W_0 is None:\n",
    "        W_0 = np.eye(D)\n",
    "        \n",
    "    # results = pd.DataFrame(columns=['step', 'train_err', 'test_err'])\n",
    "\n",
    "    for t in range(T):\n",
    "        # print(\"Step \", t)\n",
    "        # FIRST SAMPLE THE HYPERPARAMETERS, conditioned on the present step user and movie feature matrices U_t and V_t:\n",
    "\n",
    "        # parameters common to both distributions:\n",
    "        Beta_0_star = Beta_0 + N\n",
    "        nu_0_star = nu_0 + N\n",
    "        W_0_inv = np.linalg.inv(W_0)  # compute the inverse once and for all\n",
    "\n",
    "        # movie hyperparameters:\n",
    "        V_average = np.sum(V_old, axis=1) / N  # in this way it is a 1d array!!\n",
    "        # print (V_average.shape)\n",
    "        S_bar_V = np.dot(V_old, np.transpose(V_old)) / N  # CHECK IF THIS IS RIGHT!\n",
    "        mu_0_star_V = (Beta_0 * mu_0 + N * V_average) / (Beta_0 + N)\n",
    "        W_0_star_V_inv = W_0_inv + N * S_bar_V + Beta_0 * N / (Beta_0 + N) * np.dot(\n",
    "            np.transpose(np.array(mu_0 - V_average, ndmin=2)), np.array((mu_0 - V_average), ndmin=2))\n",
    "        W_0_star_V = np.linalg.inv(W_0_star_V_inv)\n",
    "        mu_V, Lambda_V, cov_V = Normal_Wishart(mu_0_star_V, Beta_0_star, W_0_star_V, nu_0_star, seed=None)\n",
    "\n",
    "        # user hyperparameters\n",
    "        # U_average=np.transpose(np.array(np.sum(U_old, axis=1)/N, ndmin=2)) #the np.array and np.transpose are needed for it to be a column vector\n",
    "        U_average = np.sum(U_old, axis=1) / N  # in this way it is a 1d array!!  #D-long\n",
    "        # print (U_average.shape)\n",
    "        S_bar_U = np.dot(U_old, np.transpose(U_old)) / N  # CHECK IF THIS IS RIGHT! #it is DxD\n",
    "        mu_0_star_U = (Beta_0 * mu_0 + N * U_average) / (Beta_0 + N)\n",
    "        W_0_star_U_inv = W_0_inv + N * S_bar_U + Beta_0 * N / (Beta_0 + N) * np.dot(\n",
    "            np.transpose(np.array(mu_0 - U_average, ndmin=2)), np.array((mu_0 - U_average), ndmin=2))\n",
    "        W_0_star_U = np.linalg.inv(W_0_star_U_inv)\n",
    "        mu_U, Lambda_U, cov_U = Normal_Wishart(mu_0_star_U, Beta_0_star, W_0_star_U, nu_0_star, seed=None)\n",
    "\n",
    "        # print (S_bar_U.shape, S_bar_V.shape)\n",
    "        # print (np.dot(np.transpose(np.array(mu_0-U_average, ndmin=2)),np.array((mu_0-U_average), ndmin=2).shape))\n",
    "\n",
    "        # UP TO HERE IT PROBABLY WORKS, FROM HERE ON IT HAS TO BE CHECKED!!!\n",
    "\n",
    "        \"\"\"SAMPLE THEN USER FEATURES (possibly in parallel):\"\"\"\n",
    "\n",
    "        U_new = np.array([])  # define the new stuff.\n",
    "        V_new = np.array([])\n",
    "\n",
    "        for i in range(N):  # loop over the users\n",
    "            # first compute the parameters of the distribution\n",
    "            Lambda_U_2 = np.zeros((D, D))  # second term in the construction of Lambda_U\n",
    "            mu_i_star_1 = np.zeros(D)  # first piece of mu_i_star\n",
    "            for j in range(M):  # loop over the movies\n",
    "                if ranked(i, j):  # only if movie j has been ranked by user i!\n",
    "                    Lambda_U_2 = Lambda_U_2 + np.dot(np.transpose(np.array(V_old[:, j], ndmin=2)),\n",
    "                                                     np.array((V_old[:, j]), ndmin=2))  # CHECK\n",
    "                    mu_i_star_1 = V_old[:, j] * R[i, j] + mu_i_star_1  # CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "                    # coeff=np.transpose(np.array(V_old[j]*R[i,j], ndmin=2))+coeff  #CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "\n",
    "            Lambda_i_star_U = Lambda_U + alpha * Lambda_U_2\n",
    "            Lambda_i_star_U_inv = np.linalg.inv(Lambda_i_star_U)\n",
    "\n",
    "            mu_i_star_part = alpha * mu_i_star_1 + np.dot(Lambda_U,\n",
    "                                                          mu_U)  ###CAREFUL!! Multiplication matrix times a row vector!! It should give as an output a row vector as for how it works\n",
    "            mu_i_star = np.dot(Lambda_i_star_U_inv, mu_i_star_part)\n",
    "            # extract now the U values!\n",
    "            U_new = np.append(U_new, multivariate_normal(mu_i_star, Lambda_i_star_U_inv))\n",
    "\n",
    "        # you need to reshape U_new and transpose it!!\n",
    "        U_new = np.transpose(np.reshape(U_new, (N, D)))\n",
    "        # print (U_new.shape)\n",
    "\n",
    "        \"\"\"SAMPLE THEN MOVIE FEATURES (possibly in parallel):\"\"\"\n",
    "\n",
    "        for j in range(M):\n",
    "            Lambda_V_2 = np.zeros((D, D))  # second term in the construction of Lambda_U\n",
    "            mu_i_star_1 = np.zeros(D)  # first piece of mu_i_star\n",
    "            for i in range(N):  # loop over the movies\n",
    "                if ranked(i, j):\n",
    "                    Lambda_V_2 = Lambda_V_2 + np.dot(np.transpose(np.array(U_new[:, i], ndmin=2)),\n",
    "                                                     np.array((U_new[:, i]), ndmin=2))\n",
    "                    mu_i_star_1 = U_new[:, i] * R[i, j] + mu_i_star_1  # CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "                    # coeff=np.transpose(np.array(V_old[j]*R[i,j], ndmin=2))+coeff  #CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "\n",
    "            Lambda_j_star_V = Lambda_V + alpha * Lambda_V_2\n",
    "            Lambda_j_star_V_inv = np.linalg.inv(Lambda_j_star_V)\n",
    "\n",
    "            mu_i_star_part = alpha * mu_i_star_1 + np.dot(Lambda_V, mu_V)\n",
    "            mu_j_star = np.dot(Lambda_j_star_V_inv, mu_i_star_part)\n",
    "            V_new = np.append(V_new, multivariate_normal(mu_j_star, Lambda_j_star_V_inv))\n",
    "\n",
    "        # you need to reshape U_new and transpose it!!\n",
    "        V_new = np.transpose(np.reshape(V_new, (M, D)))\n",
    "\n",
    "        # save U_new and V_new in U_old and V_old for next iteration:         \n",
    "        U_old = np.array(U_new)\n",
    "        V_old = np.array(V_new)\n",
    "\n",
    "        if t > initial_cutoff:  # initial_cutoff is needed to discard the initial transient\n",
    "            R_step = np.dot(np.transpose(U_new), V_new)\n",
    "            for i in range(N):  # reduce all the predictions to the correct ratings range.\n",
    "                for j in range(M):\n",
    "                    if R_step[i, j] > highest_rating:\n",
    "                        R_step[i, j] = highest_rating\n",
    "                    elif R_step[i, j] < lowest_rating:\n",
    "                        R_step[i, j] = lowest_rating\n",
    "\n",
    "            R_predict = (R_predict * (t - initial_cutoff - 1) + R_step) / (t - initial_cutoff)\n",
    "            \n",
    "            '''\n",
    "            train_err_list = []\n",
    "            train_err = 0  # initialize the errors.\n",
    "            # compute now the RMSE on the train dataset:\n",
    "            for i in range(N):\n",
    "                for j in range(M):\n",
    "                    if ranked(i, j):\n",
    "                        train_err = train_err + (R_predict[i, j] - R[i, j]) ** 2\n",
    "            train_err_list.append(np.sqrt(train_err / pairs_train))\n",
    "            print(\"Training RMSE at iteration \", t - initial_cutoff, \" :   \", \"{:.4}\".format(train_err_list[-1]))\n",
    "            '''\n",
    "            # compute now the RMSE on the test dataset:\n",
    "            test_err = 0\n",
    "            test_err_list = []\n",
    "            for i in range(N):\n",
    "                for j in range(M):\n",
    "                    if ranked_test(i, j):\n",
    "                        test_err = test_err + (R_predict[i, j] - R_test[i, j]) ** 2\n",
    "            test_err_list.append(np.sqrt(test_err / pairs_test))\n",
    "            print(\"Test RMSE at iteration \", t - initial_cutoff, \" :   \", \"{:.8}\".format(test_err_list[-1]))\n",
    "            \n",
    "    return R_predict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\\\n",
    "    R = ds.list_to_matrix(ds.trainset, ds.maxu, ds.maxi)#get matrix\n",
    "    R_test = ds.list_to_matrix(ds.testset, ds.maxu, ds.maxi)#get matrix\n",
    "    for K in [16, 32, 64]: #[8, 16, 32, 64]:\n",
    "        U_in = np.zeros((K, ds.maxu))  \n",
    "        V_in = np.zeros((K, ds.maxi))\n",
    "        nR = BPMF(R, R_test, U_in, V_in, T=10, D=K, initial_cutoff=0, lowest_rating=0, highest_rating=ds.maxr)\n",
    "        squaredError = []\n",
    "        for u,i,r in ds.testset:\n",
    "            error=r - nR[int(u)][int(i)]\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        print(\"RMSE@{}:{}\".format(K, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 0.0444\n",
      "Test RMSE at iteration  1  :    3.795553\n",
      "Test RMSE at iteration  2  :    3.7954455\n",
      "Test RMSE at iteration  3  :    3.7948991\n",
      "Test RMSE at iteration  4  :    3.7024128\n",
      "Test RMSE at iteration  5  :    3.0884098\n",
      "Test RMSE at iteration  6  :    2.6425991\n",
      "Test RMSE at iteration  7  :    2.3275106\n",
      "Test RMSE at iteration  8  :    2.0963893\n",
      "Test RMSE at iteration  9  :    1.9211684\n",
      "Test RMSE at iteration  10  :    1.7844701\n",
      "Test RMSE at iteration  11  :    1.6759191\n",
      "Test RMSE at iteration  12  :    1.5879908\n",
      "Test RMSE at iteration  13  :    1.5157115\n",
      "Test RMSE at iteration  14  :    1.4555587\n",
      "Test RMSE at iteration  15  :    1.4048477\n",
      "Test RMSE at iteration  16  :    1.3619595\n",
      "Test RMSE at iteration  17  :    1.3250328\n",
      "Test RMSE at iteration  18  :    1.2930592\n",
      "Test RMSE at iteration  19  :    1.2654148\n",
      "Test RMSE at iteration  20  :    1.2412235\n",
      "Test RMSE at iteration  21  :    1.2198003\n",
      "Test RMSE at iteration  22  :    1.2008014\n",
      "Test RMSE at iteration  23  :    1.1839192\n",
      "Test RMSE at iteration  24  :    1.1690146\n",
      "Test RMSE at iteration  25  :    1.1555737\n",
      "Test RMSE at iteration  26  :    1.1433961\n",
      "Test RMSE at iteration  27  :    1.1324301\n",
      "Test RMSE at iteration  28  :    1.1226653\n",
      "Test RMSE at iteration  29  :    1.1135829\n",
      "Test RMSE at iteration  30  :    1.105337\n",
      "Test RMSE at iteration  31  :    1.0977261\n",
      "Test RMSE at iteration  32  :    1.0907916\n",
      "Test RMSE at iteration  33  :    1.0843606\n",
      "Test RMSE at iteration  34  :    1.0785278\n",
      "Test RMSE at iteration  35  :    1.0730076\n",
      "Test RMSE at iteration  36  :    1.0680504\n",
      "Test RMSE at iteration  37  :    1.0634254\n",
      "Test RMSE at iteration  38  :    1.0590995\n",
      "Test RMSE at iteration  39  :    1.0550612\n",
      "Test RMSE at iteration  40  :    1.0512944\n",
      "Test RMSE at iteration  41  :    1.0478222\n",
      "Test RMSE at iteration  42  :    1.0445612\n",
      "Test RMSE at iteration  43  :    1.0414044\n",
      "Test RMSE at iteration  44  :    1.0385316\n",
      "Test RMSE at iteration  45  :    1.0358318\n",
      "Test RMSE at iteration  46  :    1.0332933\n",
      "Test RMSE at iteration  47  :    1.0308539\n",
      "Test RMSE at iteration  48  :    1.0285581\n",
      "Test RMSE at iteration  49  :    1.0264174\n",
      "Test RMSE at iteration  50  :    1.0244276\n",
      "Test RMSE at iteration  51  :    1.0224771\n",
      "Test RMSE at iteration  52  :    1.0206329\n",
      "Test RMSE at iteration  53  :    1.0188972\n",
      "Test RMSE at iteration  54  :    1.0172652\n",
      "Test RMSE at iteration  55  :    1.0156799\n",
      "Test RMSE at iteration  56  :    1.0141832\n",
      "Test RMSE at iteration  57  :    1.0127192\n",
      "Test RMSE at iteration  58  :    1.0113299\n",
      "Test RMSE at iteration  59  :    1.0100241\n",
      "Test RMSE at iteration  60  :    1.008782\n",
      "Test RMSE at iteration  61  :    1.0076223\n",
      "Test RMSE at iteration  62  :    1.0064823\n",
      "Test RMSE at iteration  63  :    1.0053598\n",
      "Test RMSE at iteration  64  :    1.0043477\n",
      "Test RMSE at iteration  65  :    1.0033277\n",
      "Test RMSE at iteration  66  :    1.0023833\n",
      "Test RMSE at iteration  67  :    1.0014733\n",
      "Test RMSE at iteration  68  :    1.0006049\n",
      "Test RMSE at iteration  69  :    0.99976677\n",
      "Test RMSE at iteration  70  :    0.99893979\n",
      "Test RMSE at iteration  71  :    0.99814104\n",
      "Test RMSE at iteration  72  :    0.99739934\n",
      "Test RMSE at iteration  73  :    0.99666605\n",
      "Test RMSE at iteration  74  :    0.99596189\n",
      "Test RMSE at iteration  75  :    0.995293\n",
      "Test RMSE at iteration  76  :    0.99462442\n",
      "Test RMSE at iteration  77  :    0.99396746\n",
      "Test RMSE at iteration  78  :    0.99336325\n",
      "Test RMSE at iteration  79  :    0.99274801\n",
      "Test RMSE at iteration  80  :    0.99217602\n",
      "Test RMSE at iteration  81  :    0.99165252\n",
      "Test RMSE at iteration  82  :    0.99107326\n",
      "Test RMSE at iteration  83  :    0.99056622\n",
      "Test RMSE at iteration  84  :    0.9900642\n",
      "Test RMSE at iteration  85  :    0.98956293\n",
      "Test RMSE at iteration  86  :    0.98909699\n",
      "Test RMSE at iteration  87  :    0.98864291\n",
      "Test RMSE at iteration  88  :    0.98818508\n",
      "Test RMSE at iteration  89  :    0.9877542\n",
      "Test RMSE at iteration  90  :    0.98734893\n",
      "Test RMSE at iteration  91  :    0.986927\n",
      "Test RMSE at iteration  92  :    0.98655078\n",
      "Test RMSE at iteration  93  :    0.98615475\n",
      "Test RMSE at iteration  94  :    0.98578248\n",
      "Test RMSE at iteration  95  :    0.98540421\n",
      "Test RMSE at iteration  96  :    0.98505481\n",
      "Test RMSE at iteration  97  :    0.98470333\n",
      "Test RMSE at iteration  98  :    0.98435396\n",
      "Test RMSE at iteration  99  :    0.98401523\n",
      "RMSE@16:0.9840152281449046\n",
      "Test RMSE at iteration  1  :    3.795359\n",
      "Test RMSE at iteration  2  :    3.7951637\n",
      "Test RMSE at iteration  3  :    3.793718\n",
      "Test RMSE at iteration  4  :    3.5169067\n",
      "Test RMSE at iteration  5  :    2.9119246\n",
      "Test RMSE at iteration  6  :    2.4969226\n",
      "Test RMSE at iteration  7  :    2.205704\n",
      "Test RMSE at iteration  8  :    1.9926427\n",
      "Test RMSE at iteration  9  :    1.8316743\n",
      "Test RMSE at iteration  10  :    1.7063242\n",
      "Test RMSE at iteration  11  :    1.6066847\n",
      "Test RMSE at iteration  12  :    1.5265296\n",
      "Test RMSE at iteration  13  :    1.4607846\n",
      "Test RMSE at iteration  14  :    1.406155\n",
      "Test RMSE at iteration  15  :    1.3599694\n",
      "Test RMSE at iteration  16  :    1.320952\n",
      "Test RMSE at iteration  17  :    1.2875989\n",
      "Test RMSE at iteration  18  :    1.2588799\n",
      "Test RMSE at iteration  19  :    1.2338518\n",
      "Test RMSE at iteration  20  :    1.2119909\n",
      "Test RMSE at iteration  21  :    1.1927285\n",
      "Test RMSE at iteration  22  :    1.1755858\n",
      "Test RMSE at iteration  23  :    1.1605412\n",
      "Test RMSE at iteration  24  :    1.1470686\n",
      "Test RMSE at iteration  25  :    1.135126\n",
      "Test RMSE at iteration  26  :    1.124245\n",
      "Test RMSE at iteration  27  :    1.114442\n",
      "Test RMSE at iteration  28  :    1.1055521\n",
      "Test RMSE at iteration  29  :    1.0975104\n",
      "Test RMSE at iteration  30  :    1.0901405\n",
      "Test RMSE at iteration  31  :    1.0833576\n",
      "Test RMSE at iteration  32  :    1.0771572\n",
      "Test RMSE at iteration  33  :    1.0715255\n",
      "Test RMSE at iteration  34  :    1.0662742\n",
      "Test RMSE at iteration  35  :    1.0613907\n",
      "Test RMSE at iteration  36  :    1.0569306\n",
      "Test RMSE at iteration  37  :    1.0527664\n",
      "Test RMSE at iteration  38  :    1.0488582\n",
      "Test RMSE at iteration  39  :    1.0452793\n",
      "Test RMSE at iteration  40  :    1.0419448\n",
      "Test RMSE at iteration  41  :    1.038764\n",
      "Test RMSE at iteration  42  :    1.0358891\n",
      "Test RMSE at iteration  43  :    1.0331692\n",
      "Test RMSE at iteration  44  :    1.0305662\n",
      "Test RMSE at iteration  45  :    1.0281363\n",
      "Test RMSE at iteration  46  :    1.0257873\n",
      "Test RMSE at iteration  47  :    1.0235987\n",
      "Test RMSE at iteration  48  :    1.0215914\n",
      "Test RMSE at iteration  49  :    1.0196631\n",
      "Test RMSE at iteration  50  :    1.0178019\n",
      "Test RMSE at iteration  51  :    1.0160381\n",
      "Test RMSE at iteration  52  :    1.0143724\n",
      "Test RMSE at iteration  53  :    1.0128165\n",
      "Test RMSE at iteration  54  :    1.011373\n",
      "Test RMSE at iteration  55  :    1.0099583\n",
      "Test RMSE at iteration  56  :    1.0086335\n",
      "Test RMSE at iteration  57  :    1.0073565\n",
      "Test RMSE at iteration  58  :    1.0061664\n",
      "Test RMSE at iteration  59  :    1.0050628\n",
      "Test RMSE at iteration  60  :    1.0038987\n",
      "Test RMSE at iteration  61  :    1.0028269\n",
      "Test RMSE at iteration  62  :    1.0017851\n",
      "Test RMSE at iteration  63  :    1.0008157\n",
      "Test RMSE at iteration  64  :    0.99988581\n",
      "Test RMSE at iteration  65  :    0.99898851\n",
      "Test RMSE at iteration  66  :    0.99814419\n",
      "Test RMSE at iteration  67  :    0.99732687\n",
      "Test RMSE at iteration  68  :    0.99652213\n",
      "Test RMSE at iteration  69  :    0.9958341\n",
      "Test RMSE at iteration  70  :    0.99509381\n",
      "Test RMSE at iteration  71  :    0.99440816\n",
      "Test RMSE at iteration  72  :    0.99373825\n",
      "Test RMSE at iteration  73  :    0.99307604\n",
      "Test RMSE at iteration  74  :    0.99248496\n",
      "Test RMSE at iteration  75  :    0.99185838\n",
      "Test RMSE at iteration  76  :    0.99129297\n",
      "Test RMSE at iteration  77  :    0.99067726\n",
      "Test RMSE at iteration  78  :    0.9901325\n",
      "Test RMSE at iteration  79  :    0.98958882\n",
      "Test RMSE at iteration  80  :    0.98906491\n",
      "Test RMSE at iteration  81  :    0.98856185\n",
      "Test RMSE at iteration  82  :    0.98809985\n",
      "Test RMSE at iteration  83  :    0.9876513\n",
      "Test RMSE at iteration  84  :    0.9872409\n",
      "Test RMSE at iteration  85  :    0.98678084\n",
      "Test RMSE at iteration  86  :    0.98636945\n",
      "Test RMSE at iteration  87  :    0.98596338\n",
      "Test RMSE at iteration  88  :    0.98555642\n",
      "Test RMSE at iteration  89  :    0.98517162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE at iteration  90  :    0.98480474\n",
      "Test RMSE at iteration  91  :    0.98443199\n",
      "Test RMSE at iteration  92  :    0.98410008\n",
      "Test RMSE at iteration  93  :    0.98375284\n",
      "Test RMSE at iteration  94  :    0.98342632\n",
      "Test RMSE at iteration  95  :    0.98311113\n",
      "Test RMSE at iteration  96  :    0.98280114\n",
      "Test RMSE at iteration  97  :    0.98249982\n",
      "Test RMSE at iteration  98  :    0.9821796\n",
      "Test RMSE at iteration  99  :    0.98187235\n",
      "RMSE@32:0.9818723473770827\n",
      "Test RMSE at iteration  1  :    3.7950514\n",
      "Test RMSE at iteration  2  :    3.7947319\n",
      "Test RMSE at iteration  3  :    3.7862597\n",
      "Test RMSE at iteration  4  :    3.3019665\n",
      "Test RMSE at iteration  5  :    2.7308935\n",
      "Test RMSE at iteration  6  :    2.348594\n",
      "Test RMSE at iteration  7  :    2.0817609\n",
      "Test RMSE at iteration  8  :    1.8874043\n",
      "Test RMSE at iteration  9  :    1.7409432\n",
      "Test RMSE at iteration  10  :    1.6274092\n",
      "Test RMSE at iteration  11  :    1.5375997\n",
      "Test RMSE at iteration  12  :    1.465247\n",
      "Test RMSE at iteration  13  :    1.4058913\n",
      "Test RMSE at iteration  14  :    1.3570178\n",
      "Test RMSE at iteration  15  :    1.3158636\n",
      "Test RMSE at iteration  16  :    1.2811054\n",
      "Test RMSE at iteration  17  :    1.2513268\n",
      "Test RMSE at iteration  18  :    1.2256835\n",
      "Test RMSE at iteration  19  :    1.2034347\n",
      "Test RMSE at iteration  20  :    1.184093\n",
      "Test RMSE at iteration  21  :    1.1668928\n",
      "Test RMSE at iteration  22  :    1.1517092\n",
      "Test RMSE at iteration  23  :    1.1382757\n",
      "Test RMSE at iteration  24  :    1.1262519\n",
      "Test RMSE at iteration  25  :    1.1155182\n",
      "Test RMSE at iteration  26  :    1.1058262\n",
      "Test RMSE at iteration  27  :    1.097146\n",
      "Test RMSE at iteration  28  :    1.0892611\n",
      "Test RMSE at iteration  29  :    1.0821796\n",
      "Test RMSE at iteration  30  :    1.0755533\n",
      "Test RMSE at iteration  31  :    1.0695963\n",
      "Test RMSE at iteration  32  :    1.0642425\n",
      "Test RMSE at iteration  33  :    1.0592164\n",
      "Test RMSE at iteration  34  :    1.0545536\n",
      "Test RMSE at iteration  35  :    1.0502721\n",
      "Test RMSE at iteration  36  :    1.0464115\n",
      "Test RMSE at iteration  37  :    1.0426306\n",
      "Test RMSE at iteration  38  :    1.0391875\n",
      "Test RMSE at iteration  39  :    1.0360065\n",
      "Test RMSE at iteration  40  :    1.0330741\n",
      "Test RMSE at iteration  41  :    1.0303151\n",
      "Test RMSE at iteration  42  :    1.0277154\n",
      "Test RMSE at iteration  43  :    1.0252342\n",
      "Test RMSE at iteration  44  :    1.0229741\n",
      "Test RMSE at iteration  45  :    1.0207432\n",
      "Test RMSE at iteration  46  :    1.0187679\n",
      "Test RMSE at iteration  47  :    1.0168619\n",
      "Test RMSE at iteration  48  :    1.0150468\n",
      "Test RMSE at iteration  49  :    1.0133313\n",
      "Test RMSE at iteration  50  :    1.0117264\n",
      "Test RMSE at iteration  51  :    1.0101785\n",
      "Test RMSE at iteration  52  :    1.0087311\n",
      "Test RMSE at iteration  53  :    1.0073671\n",
      "Test RMSE at iteration  54  :    1.006074\n",
      "Test RMSE at iteration  55  :    1.0048388\n",
      "Test RMSE at iteration  56  :    1.0036375\n",
      "Test RMSE at iteration  57  :    1.0025393\n",
      "Test RMSE at iteration  58  :    1.0015009\n",
      "Test RMSE at iteration  59  :    1.0005024\n",
      "Test RMSE at iteration  60  :    0.99949921\n",
      "Test RMSE at iteration  61  :    0.9985837\n",
      "Test RMSE at iteration  62  :    0.99770723\n",
      "Test RMSE at iteration  63  :    0.99683676\n",
      "Test RMSE at iteration  64  :    0.99602773\n",
      "Test RMSE at iteration  65  :    0.99529746\n",
      "Test RMSE at iteration  66  :    0.9945928\n",
      "Test RMSE at iteration  67  :    0.99387136\n",
      "Test RMSE at iteration  68  :    0.99320842\n",
      "Test RMSE at iteration  69  :    0.99254331\n",
      "Test RMSE at iteration  70  :    0.99188723\n",
      "Test RMSE at iteration  71  :    0.99126951\n",
      "Test RMSE at iteration  72  :    0.99065423\n",
      "Test RMSE at iteration  73  :    0.99009662\n",
      "Test RMSE at iteration  74  :    0.98948582\n",
      "Test RMSE at iteration  75  :    0.98896271\n",
      "Test RMSE at iteration  76  :    0.98845449\n",
      "Test RMSE at iteration  77  :    0.98796174\n",
      "Test RMSE at iteration  78  :    0.98748648\n",
      "Test RMSE at iteration  79  :    0.98702522\n",
      "Test RMSE at iteration  80  :    0.98654902\n",
      "Test RMSE at iteration  81  :    0.98612184\n",
      "Test RMSE at iteration  82  :    0.98571642\n",
      "Test RMSE at iteration  83  :    0.98529066\n",
      "Test RMSE at iteration  84  :    0.98487667\n",
      "Test RMSE at iteration  85  :    0.98446977\n",
      "Test RMSE at iteration  86  :    0.98407321\n",
      "Test RMSE at iteration  87  :    0.98367541\n",
      "Test RMSE at iteration  88  :    0.98323688\n",
      "Test RMSE at iteration  89  :    0.98250934\n",
      "Test RMSE at iteration  90  :    0.98158124\n",
      "Test RMSE at iteration  91  :    0.98055009\n",
      "Test RMSE at iteration  92  :    0.97957066\n",
      "Test RMSE at iteration  93  :    0.97860308\n",
      "Test RMSE at iteration  94  :    0.97765723\n",
      "Test RMSE at iteration  95  :    0.97677938\n",
      "Test RMSE at iteration  96  :    0.97581568\n",
      "Test RMSE at iteration  97  :    0.97491799\n",
      "Test RMSE at iteration  98  :    0.97400245\n",
      "Test RMSE at iteration  99  :    0.97312141\n",
      "RMSE@64:0.9731214107557015\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.08.01\n",
    "@function: baseline: BPMF(Bayesian Probabilistic Matrix Factorization)\n",
    "           paper: https://dl.acm.org/citation.cfm?id=1390267\n",
    "           Datatset: MovieLens-1m:https://grouplens.org/datasets/movielens/  \n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.stats import wishart\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.train.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        maxu, maxi, maxr = data['user'].max()+1, data['item'].max()+1, data['rating'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.test.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "    \n",
    "def Normal_Wishart(mu_0, lamb, W, nu, seed=None):\n",
    "    \"\"\"Function extracting a Normal_Wishart random variable\"\"\"\n",
    "    # first draw a Wishart distribution:\n",
    "    Lambda = wishart(df=nu, scale=W, seed=seed).rvs()  # NB: Lambda is a matrix.\n",
    "    # then draw a Gaussian multivariate RV with mean mu_0 and(lambda*Lambda)^{-1} as covariance matrix.\n",
    "    cov = np.linalg.inv(lamb * Lambda)  # this is the bottleneck!!\n",
    "    mu = multivariate_normal(mu_0, cov)\n",
    "    return mu, Lambda, cov\n",
    "\n",
    "def BPMF(R, R_test, U_in, V_in, T, D, initial_cutoff, lowest_rating, highest_rating,\n",
    "         mu_0=None, Beta_0=None, W_0=None, nu_0=None):\n",
    "    \"\"\"\n",
    "    R is the ranking matrix (NxM, N=#users, M=#movies); we are assuming that R[i,j]=0 means that user i has not ranked movie j\n",
    "    R_test is the ranking matrix that contains test values. Same assumption as above. \n",
    "    U_in, V_in are the initial values for the MCMC procedure. \n",
    "    T is the number of steps. \n",
    "    D is the number of hidden features that are assumed in the model.    \n",
    "    \n",
    "    mu_0 is the average vector used in sampling the multivariate normal variable\n",
    "    Beta_0 is a coefficient (?)\n",
    "    W_0 is the DxD scale matrix in the Wishart sampling \n",
    "    nu_0 is the number of degrees of freedom used in the Wishart sampling. \n",
    "    \n",
    "    U matrices are DxN, while V matrices are DxM.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def ranked(i, j):  # function telling if user i ranked movie j in the train dataset.\n",
    "        if R[i, j] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def ranked_test(i, j):  # function telling if user i ranked movie j in the test dataset.\n",
    "        if R_test[i, j] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    N = R.shape[0]\n",
    "    M = R.shape[1]\n",
    "\n",
    "    R_predict = np.zeros((N, M))\n",
    "    U_old = np.array(U_in)\n",
    "    V_old = np.array(V_in)\n",
    "\n",
    "    # initialize now the hierarchical priors:\n",
    "    alpha = 2  # observation noise, they put it = 2 in the paper\n",
    "    mu_u = np.zeros((D, 1))\n",
    "    mu_v = np.zeros((D, 1))\n",
    "    Lambda_U = np.eye(D)\n",
    "    Lambda_V = np.eye(D)\n",
    "\n",
    "    # COUNT HOW MAY PAIRS ARE IN THE TEST AND TRAIN SET:\n",
    "    pairs_test = 0\n",
    "    pairs_train = 0\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            if ranked(i, j):\n",
    "                pairs_train = pairs_train + 1\n",
    "            if ranked_test(i, j):\n",
    "                pairs_test = pairs_test + 1\n",
    "\n",
    "    # print(pairs_test, pairs_train)\n",
    "\n",
    "    # SET THE DEFAULT VALUES for Wishart distribution\n",
    "    # we assume that parameters for both U and V are the same.\n",
    "\n",
    "    if mu_0 is None:\n",
    "        mu_0 = np.zeros(D)\n",
    "    if nu_0 is None:\n",
    "        nu_0 = D\n",
    "    if Beta_0 is None:\n",
    "        Beta_0 = 2\n",
    "    if W_0 is None:\n",
    "        W_0 = np.eye(D)\n",
    "        \n",
    "    # results = pd.DataFrame(columns=['step', 'train_err', 'test_err'])\n",
    "\n",
    "    for t in range(T):\n",
    "        # print(\"Step \", t)\n",
    "        # FIRST SAMPLE THE HYPERPARAMETERS, conditioned on the present step user and movie feature matrices U_t and V_t:\n",
    "\n",
    "        # parameters common to both distributions:\n",
    "        Beta_0_star = Beta_0 + N\n",
    "        nu_0_star = nu_0 + N\n",
    "        W_0_inv = np.linalg.inv(W_0)  # compute the inverse once and for all\n",
    "\n",
    "        # movie hyperparameters:\n",
    "        V_average = np.sum(V_old, axis=1) / N  # in this way it is a 1d array!!\n",
    "        # print (V_average.shape)\n",
    "        S_bar_V = np.dot(V_old, np.transpose(V_old)) / N  # CHECK IF THIS IS RIGHT!\n",
    "        mu_0_star_V = (Beta_0 * mu_0 + N * V_average) / (Beta_0 + N)\n",
    "        W_0_star_V_inv = W_0_inv + N * S_bar_V + Beta_0 * N / (Beta_0 + N) * np.dot(\n",
    "            np.transpose(np.array(mu_0 - V_average, ndmin=2)), np.array((mu_0 - V_average), ndmin=2))\n",
    "        W_0_star_V = np.linalg.inv(W_0_star_V_inv)\n",
    "        mu_V, Lambda_V, cov_V = Normal_Wishart(mu_0_star_V, Beta_0_star, W_0_star_V, nu_0_star, seed=None)\n",
    "\n",
    "        # user hyperparameters\n",
    "        # U_average=np.transpose(np.array(np.sum(U_old, axis=1)/N, ndmin=2)) #the np.array and np.transpose are needed for it to be a column vector\n",
    "        U_average = np.sum(U_old, axis=1) / N  # in this way it is a 1d array!!  #D-long\n",
    "        # print (U_average.shape)\n",
    "        S_bar_U = np.dot(U_old, np.transpose(U_old)) / N  # CHECK IF THIS IS RIGHT! #it is DxD\n",
    "        mu_0_star_U = (Beta_0 * mu_0 + N * U_average) / (Beta_0 + N)\n",
    "        W_0_star_U_inv = W_0_inv + N * S_bar_U + Beta_0 * N / (Beta_0 + N) * np.dot(\n",
    "            np.transpose(np.array(mu_0 - U_average, ndmin=2)), np.array((mu_0 - U_average), ndmin=2))\n",
    "        W_0_star_U = np.linalg.inv(W_0_star_U_inv)\n",
    "        mu_U, Lambda_U, cov_U = Normal_Wishart(mu_0_star_U, Beta_0_star, W_0_star_U, nu_0_star, seed=None)\n",
    "\n",
    "        # print (S_bar_U.shape, S_bar_V.shape)\n",
    "        # print (np.dot(np.transpose(np.array(mu_0-U_average, ndmin=2)),np.array((mu_0-U_average), ndmin=2).shape))\n",
    "\n",
    "        # UP TO HERE IT PROBABLY WORKS, FROM HERE ON IT HAS TO BE CHECKED!!!\n",
    "\n",
    "        \"\"\"SAMPLE THEN USER FEATURES (possibly in parallel):\"\"\"\n",
    "\n",
    "        U_new = np.array([])  # define the new stuff.\n",
    "        V_new = np.array([])\n",
    "\n",
    "        for i in range(N):  # loop over the users\n",
    "            # first compute the parameters of the distribution\n",
    "            Lambda_U_2 = np.zeros((D, D))  # second term in the construction of Lambda_U\n",
    "            mu_i_star_1 = np.zeros(D)  # first piece of mu_i_star\n",
    "            for j in range(M):  # loop over the movies\n",
    "                if ranked(i, j):  # only if movie j has been ranked by user i!\n",
    "                    Lambda_U_2 = Lambda_U_2 + np.dot(np.transpose(np.array(V_old[:, j], ndmin=2)),\n",
    "                                                     np.array((V_old[:, j]), ndmin=2))  # CHECK\n",
    "                    mu_i_star_1 = V_old[:, j] * R[i, j] + mu_i_star_1  # CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "                    # coeff=np.transpose(np.array(V_old[j]*R[i,j], ndmin=2))+coeff  #CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "\n",
    "            Lambda_i_star_U = Lambda_U + alpha * Lambda_U_2\n",
    "            Lambda_i_star_U_inv = np.linalg.inv(Lambda_i_star_U)\n",
    "\n",
    "            mu_i_star_part = alpha * mu_i_star_1 + np.dot(Lambda_U,\n",
    "                                                          mu_U)  ###CAREFUL!! Multiplication matrix times a row vector!! It should give as an output a row vector as for how it works\n",
    "            mu_i_star = np.dot(Lambda_i_star_U_inv, mu_i_star_part)\n",
    "            # extract now the U values!\n",
    "            U_new = np.append(U_new, multivariate_normal(mu_i_star, Lambda_i_star_U_inv))\n",
    "\n",
    "        # you need to reshape U_new and transpose it!!\n",
    "        U_new = np.transpose(np.reshape(U_new, (N, D)))\n",
    "        # print (U_new.shape)\n",
    "\n",
    "        \"\"\"SAMPLE THEN MOVIE FEATURES (possibly in parallel):\"\"\"\n",
    "\n",
    "        for j in range(M):\n",
    "            Lambda_V_2 = np.zeros((D, D))  # second term in the construction of Lambda_U\n",
    "            mu_i_star_1 = np.zeros(D)  # first piece of mu_i_star\n",
    "            for i in range(N):  # loop over the movies\n",
    "                if ranked(i, j):\n",
    "                    Lambda_V_2 = Lambda_V_2 + np.dot(np.transpose(np.array(U_new[:, i], ndmin=2)),\n",
    "                                                     np.array((U_new[:, i]), ndmin=2))\n",
    "                    mu_i_star_1 = U_new[:, i] * R[i, j] + mu_i_star_1  # CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "                    # coeff=np.transpose(np.array(V_old[j]*R[i,j], ndmin=2))+coeff  #CHECK DIMENSIONALITY!!!!!!!!!!!!\n",
    "\n",
    "            Lambda_j_star_V = Lambda_V + alpha * Lambda_V_2\n",
    "            Lambda_j_star_V_inv = np.linalg.inv(Lambda_j_star_V)\n",
    "\n",
    "            mu_i_star_part = alpha * mu_i_star_1 + np.dot(Lambda_V, mu_V)\n",
    "            mu_j_star = np.dot(Lambda_j_star_V_inv, mu_i_star_part)\n",
    "            V_new = np.append(V_new, multivariate_normal(mu_j_star, Lambda_j_star_V_inv))\n",
    "\n",
    "        # you need to reshape U_new and transpose it!!\n",
    "        V_new = np.transpose(np.reshape(V_new, (M, D)))\n",
    "\n",
    "        # save U_new and V_new in U_old and V_old for next iteration:         \n",
    "        U_old = np.array(U_new)\n",
    "        V_old = np.array(V_new)\n",
    "\n",
    "        if t > initial_cutoff:  # initial_cutoff is needed to discard the initial transient\n",
    "            R_step = np.dot(np.transpose(U_new), V_new)\n",
    "            for i in range(N):  # reduce all the predictions to the correct ratings range.\n",
    "                for j in range(M):\n",
    "                    if R_step[i, j] > highest_rating:\n",
    "                        R_step[i, j] = highest_rating\n",
    "                    elif R_step[i, j] < lowest_rating:\n",
    "                        R_step[i, j] = lowest_rating\n",
    "\n",
    "            R_predict = (R_predict * (t - initial_cutoff - 1) + R_step) / (t - initial_cutoff)\n",
    "            \n",
    "            '''\n",
    "            train_err_list = []\n",
    "            train_err = 0  # initialize the errors.\n",
    "            # compute now the RMSE on the train dataset:\n",
    "            for i in range(N):\n",
    "                for j in range(M):\n",
    "                    if ranked(i, j):\n",
    "                        train_err = train_err + (R_predict[i, j] - R[i, j]) ** 2\n",
    "            train_err_list.append(np.sqrt(train_err / pairs_train))\n",
    "            print(\"Training RMSE at iteration \", t - initial_cutoff, \" :   \", \"{:.4}\".format(train_err_list[-1]))\n",
    "            '''\n",
    "            # compute now the RMSE on the test dataset:\n",
    "            test_err = 0\n",
    "            test_err_list = []\n",
    "            for i in range(N):\n",
    "                for j in range(M):\n",
    "                    if ranked_test(i, j):\n",
    "                        test_err = test_err + (R_predict[i, j] - R_test[i, j]) ** 2\n",
    "            test_err_list.append(np.sqrt(test_err / pairs_test))\n",
    "            print(\"Test RMSE at iteration \", t - initial_cutoff, \" :   \", \"{:.8}\".format(test_err_list[-1]))\n",
    "            \n",
    "    return R_predict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\\\n",
    "    R = ds.list_to_matrix(ds.trainset, ds.maxu, ds.maxi)#get matrix\n",
    "    R_test = ds.list_to_matrix(ds.testset, ds.maxu, ds.maxi)#get matrix\n",
    "    for K in [16, 32, 64]: #[8, 16, 32, 64]:\n",
    "        U_in = np.zeros((K, ds.maxu))  \n",
    "        V_in = np.zeros((K, ds.maxi))\n",
    "        nR = BPMF(R, R_test, U_in, V_in, T=100, D=K, initial_cutoff=0, lowest_rating=0, highest_rating=ds.maxr)\n",
    "        squaredError = []\n",
    "        for u,i,r in ds.testset:\n",
    "            error=r - nR[int(u)][int(i)]\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        print(\"RMSE@{}:{}\".format(K, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/theano/tensor/basic.py:6611: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result[diagonal_slice] = x\n",
      "Average Loss = inf:   0%|          | 1/1000 [00:01<19:15,  1.16s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs\nApply node that caused the error: Cholesky{lower=True, destructive=False, on_error='nan'}(MatrixInverse.0)\nToposort index: 118\nInputs types: [TensorType(float64, matrix)]\nInputs shapes: [(8, 8)]\nInputs strides: [(64, 8)]\nInputs values: ['not shown']\nOutputs clients: [[ExtractDiag{offset=0, axis1=0, axis2=1, view=False}(Cholesky{lower=True, destructive=False, on_error='nan'}.0), Elemwise{isnan,no_inplace}(Cholesky{lower=True, destructive=False, on_error='nan'}.0), Elemwise{switch,no_inplace}(Elemwise{Invert}[(0, 0)].0, Cholesky{lower=True, destructive=False, on_error='nan'}.0, TensorConstant{(1, 1) of 1}), Elemwise{Switch}[(0, 1)](InplaceDimShuffle{x,x}.0, Cholesky{lower=True, destructive=False, on_error='nan'}.0, TensorConstant{(1, 1) of 1})]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-933b6988c11b>\", line 136, in <module>\n    bpmf = build_bpmf_model(train=R, dim=K)#dim is the number of latent factors\n  File \"<ipython-input-3-933b6988c11b>\", line 91, in build_bpmf_model\n    U = pm.MvNormal('U', mu=mu_u, tau=lambda_u, shape=(n, dim),testval=np.random.randn(n, dim) * std)\n  File \"/usr/local/lib/python3.6/dist-packages/pymc3/distributions/distribution.py\", line 45, in __new__\n    dist = cls.dist(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/pymc3/distributions/distribution.py\", line 56, in dist\n    dist.__init__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/pymc3/distributions/multivariate.py\", line 225, in __init__\n    super().__init__(mu=mu, cov=cov, tau=tau, chol=chol, lower=lower, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/pymc3/distributions/multivariate.py\", line 71, in __init__\n    self.chol_tau = cholesky(tau)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/tensor/slinalg.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, outputs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m     90\u001b[0m     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n\u001b[0;32m---> 91\u001b[0;31m                          check_finite=check_finite)\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    497\u001b[0m         raise ValueError(\n\u001b[0;32m--> 498\u001b[0;31m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-933b6988c11b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mtstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting BPMF training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mapprox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mADVI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapprox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m#start = pm.find_MAP()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymc3/variational/inference.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(n, local_rv, method, model, random_seed, start, inf_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m                         \u001b[0;34m'or Inference instance'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                         set(_select.keys()))\n\u001b[0;32m--> 790\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymc3/variational/inference.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n, score, callbacks, progressbar, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mprogressbar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterate_with_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterate_without_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymc3/variational/inference.py\u001b[0m in \u001b[0;36m_iterate_with_loss\u001b[0;34m(self, s, n, step_func, progress, callbacks)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/tensor/slinalg.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, outputs)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_error\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \"\"\"\n\u001b[1;32m     90\u001b[0m     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n\u001b[0;32m---> 91\u001b[0;31m                          check_finite=check_finite)\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Common code for cholesky() and cho_factor().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         raise ValueError(\n\u001b[0;32m--> 498\u001b[0;31m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs\nApply node that caused the error: Cholesky{lower=True, destructive=False, on_error='nan'}(MatrixInverse.0)\nToposort index: 118\nInputs types: [TensorType(float64, matrix)]\nInputs shapes: [(8, 8)]\nInputs strides: [(64, 8)]\nInputs values: ['not shown']\nOutputs clients: [[ExtractDiag{offset=0, axis1=0, axis2=1, view=False}(Cholesky{lower=True, destructive=False, on_error='nan'}.0), Elemwise{isnan,no_inplace}(Cholesky{lower=True, destructive=False, on_error='nan'}.0), Elemwise{switch,no_inplace}(Elemwise{Invert}[(0, 0)].0, Cholesky{lower=True, destructive=False, on_error='nan'}.0, TensorConstant{(1, 1) of 1}), Elemwise{Switch}[(0, 1)](InplaceDimShuffle{x,x}.0, Cholesky{lower=True, destructive=False, on_error='nan'}.0, TensorConstant{(1, 1) of 1})]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-933b6988c11b>\", line 136, in <module>\n    bpmf = build_bpmf_model(train=R, dim=K)#dim is the number of latent factors\n  File \"<ipython-input-3-933b6988c11b>\", line 91, in build_bpmf_model\n    U = pm.MvNormal('U', mu=mu_u, tau=lambda_u, shape=(n, dim),testval=np.random.randn(n, dim) * std)\n  File \"/usr/local/lib/python3.6/dist-packages/pymc3/distributions/distribution.py\", line 45, in __new__\n    dist = cls.dist(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/pymc3/distributions/distribution.py\", line 56, in dist\n    dist.__init__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/pymc3/distributions/multivariate.py\", line 225, in __init__\n    super().__init__(mu=mu, cov=cov, tau=tau, chol=chol, lower=lower, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/pymc3/distributions/multivariate.py\", line 71, in __init__\n    self.chol_tau = cholesky(tau)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.07.31\n",
    "@function: baseline: BPMF(Bayesian Probabilistic Matrix Factorization)\n",
    "           paper: https://dl.acm.org/citation.cfm?id=1401944\n",
    "           Datatset: MovieLens-1m:https://grouplens.org/datasets/movielens/  \n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import heapq\n",
    "import math\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.train.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        maxu, maxi, maxr = data['user'].max()+1, data['item'].max()+1, data['rating'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.test.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "'''  \n",
    "def build_bpmf_model(train, dim, alpha=2, std=0.01):\n",
    "    \"\"\"Build the modified BPMF model using pymc3. The original model uses\n",
    "    Wishart priors on the covariance matrices. Unfortunately, the Wishart\n",
    "    distribution in pymc3 is currently not suitable for sampling. This\n",
    "    version decomposes the covariance matrix into:\n",
    "        diag(sigma) \\dot corr_matrix \\dot diag(std).\n",
    "    We use uniform priors on the standard deviations (sigma) and LKJCorr\n",
    "    priors on the correlation matrices (corr_matrix):\n",
    "        sigma ~ Uniform\n",
    "        corr_matrix ~ LKJCorr(n=1, p=dim)\n",
    "    \"\"\"\n",
    "    n, m = train.shape\n",
    "    beta_0 = 1  # scaling factor for lambdas; unclear on its use\n",
    " \n",
    "    # Mean value imputation on training data.\n",
    "    train = train.copy()\n",
    "    nan_mask = np.isnan(train)\n",
    "    train[nan_mask] = train[~nan_mask].mean()\n",
    " \n",
    "    # We will use separate priors for sigma and correlation matrix.\n",
    "    # In order to convert the upper triangular correlation values to a\n",
    "    # complete correlation matrix, we need to construct an index matrix:\n",
    "    n_elem = int(dim * (dim - 1) / 2)\n",
    "    tri_index = np.zeros([dim, dim], dtype=int)\n",
    "    tri_index[np.triu_indices(dim, k=1)] = np.arange(n_elem)\n",
    "    tri_index[np.triu_indices(dim, k=1)[::-1]] = np.arange(n_elem)\n",
    " \n",
    "    logging.info('building the BPMF model')\n",
    "    with pm.Model() as bpmf:\n",
    "        # Specify user feature matrix\n",
    "        sigma_u = pm.Uniform('sigma_u', shape=dim)\n",
    "        corr_triangle_u = pm.LKJCorr('corr_u', n=1, p=dim, testval=np.random.randn(n_elem) * std)\n",
    " \n",
    "        corr_matrix_u = corr_triangle_u[tri_index]\n",
    "        corr_matrix_u = tt.fill_diagonal(corr_matrix_u, 1)\n",
    "        cov_matrix_u = tt.diag(sigma_u).dot(corr_matrix_u.dot(tt.diag(sigma_u)))\n",
    "        lambda_u = tt.nlinalg.matrix_inverse(cov_matrix_u)\n",
    " \n",
    "        mu_u = pm.Normal('mu_u', mu=0, tau=beta_0 * tt.diag(lambda_u), shape=dim,testval=np.random.randn(dim) * std)\n",
    "        U = pm.MvNormal('U', mu=mu_u, tau=lambda_u, shape=(n, dim),testval=np.random.randn(n, dim) * std)\n",
    " \n",
    "        # Specify item feature matrix\n",
    "        sigma_v = pm.Uniform('sigma_v', shape=dim)\n",
    "        corr_triangle_v = pm.LKJCorr('corr_v', n=1, p=dim,testval=np.random.randn(n_elem) * std)\n",
    " \n",
    "        corr_matrix_v = corr_triangle_v[tri_index]\n",
    "        corr_matrix_v = tt.fill_diagonal(corr_matrix_v, 1)\n",
    "        cov_matrix_v = tt.diag(sigma_v).dot(corr_matrix_v.dot(tt.diag(sigma_v)))\n",
    "        lambda_v = tt.nlinalg.matrix_inverse(cov_matrix_v)\n",
    " \n",
    "        mu_v = pm.Normal('mu_v', mu=0, tau=beta_0 * tt.diag(lambda_v), shape=dim,testval=np.random.randn(dim) * std)\n",
    "        V = pm.MvNormal( 'V', mu=mu_v, tau=lambda_v, shape=(m, dim),testval=np.random.randn(m, dim) * std)\n",
    " \n",
    "        # Specify rating likelihood function\n",
    "        R = pm.Normal('R', mu=tt.dot(U, V.T), tau=alpha * np.ones((n, m)),observed=train)\n",
    " \n",
    "    logging.info('done building the BPMF model')\n",
    "    return bpmf\n",
    "'''\n",
    "def build_bpmf_model(train, dim, alpha=2, std=0.01):\n",
    "    # Mean value imputation on training data.\n",
    "    train = train.copy()\n",
    "    nan_mask = np.isnan(train)\n",
    "    train[nan_mask] = train[~nan_mask].mean()\n",
    " \n",
    "    # Low precision reflects uncertainty; prevents overfitting.\n",
    "    # We use point estimates from the data to intialize.\n",
    "    # Set to mean variance across users and items.\n",
    "    alpha_u = 1 / train.var(axis=1).mean()\n",
    "    alpha_v = 1 / train.var(axis=0).mean()\n",
    " \n",
    "    logging.info('building the BPMF model')\n",
    "    n, m = train.shape\n",
    "    with pm.Model() as bpmf:\n",
    "        U = pm.MvNormal('U', mu=0, tau=alpha_u * np.eye(dim),shape=(n, dim), testval=np.random.randn(n, dim) * std)\n",
    "        V = pm.MvNormal('V', mu=0, tau=alpha_v * np.eye(dim),shape=(m, dim), testval=np.random.randn(m, dim) * std)\n",
    "        R = pm.Normal('R', mu=tt.dot(U, V.T), tau=alpha * np.ones(train.shape),observed=train)\n",
    "    logging.info('done building BPMF model')\n",
    "    return bpmf\n",
    "   \n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\\\n",
    "    R = ds.list_to_matrix(ds.trainset, ds.maxu, ds.maxi)#get matrix\n",
    "    for K in [8, 16, 32, 64]:\n",
    "        bpmf = build_bpmf_model(train=R, dim=K)#dim is the number of latent factors\n",
    "        with bpmf:# sample with BPMF\n",
    "            tstart = time.time()\n",
    "            logging.info('Starting BPMF training')\n",
    "            approx = pm.fit(n=1000, method=pm.ADVI())\n",
    "            trace = approx.sample(draws=500)\n",
    "            #start = pm.find_MAP()    \n",
    "            #step = pm.NUTS()\n",
    "            #trace = pm.sample(1000, step=step, start=start)\n",
    "            elapsed = time.time() - tstart    \n",
    "            logging.info('Completed BPMF in %d seconds' % int(elapsed))\n",
    "        \n",
    "        with bpmf:#evaluation\n",
    "            ppc = pm.sample_posterior_predictive(trace, progressbar=True)\n",
    "            nR = np.mean(ppc['R'],0)#three dims, calcuate the mean with the first dim for posterior\n",
    "\n",
    "        squaredError = []\n",
    "        for u,i,r in ds.testset:\n",
    "            error=r - nR[int(u)][int(i)]\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        print(\"RMSE@{}:{}\".format(K, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Model: BMF(Bayesian Matrix Factorization for Recommeder Systems).\n",
    "2. Datatset: MovieLens-1m:https://grouplens.org/datasets/movielens/  \n",
    "3. Evaluation: HR,NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import heapq\n",
    "import math\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import surprise as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of metrics\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0\n",
    "#dataset\n",
    "class DataSet_1M(object):\n",
    "    def __init__(self, negNum=2):\n",
    "        self.trainList, self.shape = self._getTrainData()\n",
    "        self.trainDict = self._getTrainDict()\n",
    "        self.trainMat = self._getTrainMatrix()\n",
    "        self.trainset = self._getInstances(negNum)#sample negative samples\n",
    "        self.testset = self._getTest()\n",
    "        \n",
    "    def _getTrainData(self):\n",
    "        data = []\n",
    "        filePath = '/data/fjsdata/BNMF/ml-1m.train.rating'\n",
    "        u = 0\n",
    "        i = 0\n",
    "        maxr = 0.0\n",
    "        with open(filePath, 'r') as f:\n",
    "            for line in f:\n",
    "                if line:\n",
    "                    lines = line[:-1].split(\"\\t\")\n",
    "                    user = int(lines[0])\n",
    "                    movie = int(lines[1])\n",
    "                    score = float(lines[2])\n",
    "                    data.append((user, movie, score))\n",
    "                    if user > u:u = user\n",
    "                    if movie > i:i = movie\n",
    "                    if score > maxr:maxr = score\n",
    "        self.maxRate = maxr\n",
    "        print(\"Loading Success!\\n\"\n",
    "                  \"Data Info:\\n\"\n",
    "                  \"\\tUser Num: {}\\n\"\n",
    "                  \"\\tItem Num: {}\\n\"\n",
    "                  \"\\tData Size: {}\\n\"\n",
    "                  \"\\tSparsity: {}\".format(u+1, i+1, len(data), len(data)/((u+1)*(i+1))))\n",
    "        return data, [u+1, i+1]\n",
    "\n",
    "    def _getTrainDict(self):\n",
    "        dataDict = {}\n",
    "        for i in self.trainList:\n",
    "            dataDict[(i[0], i[1])] = i[2]\n",
    "        return dataDict\n",
    "\n",
    "    def _getTrainMatrix(self):\n",
    "        train_matrix = np.zeros([self.shape[0], self.shape[1]], dtype=np.float32)\n",
    "        for i in self.trainList:\n",
    "            user = i[0]\n",
    "            movie = i[1]\n",
    "            rating = i[2]\n",
    "            train_matrix[user][movie] = rating\n",
    "        return np.array(train_matrix)\n",
    "\n",
    "    def _getInstances(self, negNum):\n",
    "        trainset = []\n",
    "        for i in self.trainList:\n",
    "            trainset.append([i[0],i[1],i[2]])\n",
    "            for t in range(negNum):\n",
    "                j = np.random.randint(self.shape[1])\n",
    "                while (i[0], j) in self.trainDict:\n",
    "                    j = np.random.randint(self.shape[1])\n",
    "                trainset.append([i[0],j,0.0])\n",
    "        print ('The length of Trainset: %d'%(len(trainset)))\n",
    "        return trainset\n",
    "\n",
    "    def _getTest(self):\n",
    "        #loading data\n",
    "        testset = []\n",
    "        filePath = '/data/fjsdata/BNMF/ml-1m.test.negative'\n",
    "        with open(filePath, 'r') as fd:\n",
    "            line = fd.readline()\n",
    "            while line != None and line != '':\n",
    "                arr = line.split('\\t')\n",
    "                u = eval(arr[0])[0]\n",
    "                testset.append([u, eval(arr[0])[1], 1.0])#first is one postive item\n",
    "                for i in arr[1:]:\n",
    "                    testset.append([u, int(i), 0.0]) #99 negative items\n",
    "                line = fd.readline()\n",
    "        print ('The length of Testset: %d'%(len(testset)))\n",
    "        return testset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Baseline: SVD with scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 994169\n",
      "The length of Testset: 604000\n",
      "Completed training the SVD model in 21 seconds\n",
      "HR@5@0=0.258444, NDCG@5@0=0.126514\n",
      "Completed training the SVD model in 24 seconds\n",
      "HR@10@0=0.258278, NDCG@10@0=0.126331\n",
      "Completed training the SVD model in 28 seconds\n",
      "HR@15@0=0.259106, NDCG@15@0=0.127861\n",
      "Completed training the SVD model in 31 seconds\n",
      "HR@20@0=0.256291, NDCG@20@0=0.126698\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 1988338\n",
      "The length of Testset: 604000\n",
      "Completed training the SVD model in 42 seconds\n",
      "HR@5@1=0.450662, NDCG@5@1=0.247204\n",
      "Completed training the SVD model in 49 seconds\n",
      "HR@10@1=0.455629, NDCG@10@1=0.252744\n",
      "Completed training the SVD model in 57 seconds\n",
      "HR@15@1=0.461589, NDCG@15@1=0.253892\n",
      "Completed training the SVD model in 63 seconds\n",
      "HR@20@1=0.467550, NDCG@20@1=0.257028\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 2982507\n",
      "The length of Testset: 604000\n",
      "Completed training the SVD model in 64 seconds\n",
      "HR@5@2=0.491060, NDCG@5@2=0.271704\n",
      "Completed training the SVD model in 73 seconds\n",
      "HR@10@2=0.505795, NDCG@10@2=0.284282\n",
      "Completed training the SVD model in 90 seconds\n",
      "HR@15@2=0.510927, NDCG@15@2=0.286753\n",
      "Completed training the SVD model in 105 seconds\n",
      "HR@20@2=0.515232, NDCG@20@2=0.289833\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 3976676\n",
      "The length of Testset: 604000\n",
      "Completed training the SVD model in 86 seconds\n",
      "HR@5@3=0.512583, NDCG@5@3=0.286711\n",
      "Completed training the SVD model in 100 seconds\n",
      "HR@10@3=0.519536, NDCG@10@3=0.294336\n",
      "Completed training the SVD model in 114 seconds\n",
      "HR@15@3=0.533609, NDCG@15@3=0.301337\n",
      "Completed training the SVD model in 128 seconds\n",
      "HR@20@3=0.541391, NDCG@20@3=0.307956\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 4970845\n",
      "The length of Testset: 604000\n",
      "Completed training the SVD model in 108 seconds\n",
      "HR@5@4=0.525828, NDCG@5@4=0.299543\n",
      "Completed training the SVD model in 124 seconds\n",
      "HR@10@4=0.547848, NDCG@10@4=0.311370\n",
      "Completed training the SVD model in 142 seconds\n",
      "HR@15@4=0.549503, NDCG@15@4=0.311992\n",
      "Completed training the SVD model in 160 seconds\n",
      "HR@20@4=0.561921, NDCG@20@4=0.319785\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 5965014\n",
      "The length of Testset: 604000\n",
      "Completed training the SVD model in 132 seconds\n",
      "HR@5@5=0.528808, NDCG@5@5=0.296449\n",
      "Completed training the SVD model in 149 seconds\n",
      "HR@10@5=0.551325, NDCG@10@5=0.313380\n",
      "Completed training the SVD model in 173 seconds\n",
      "HR@15@5=0.557450, NDCG@15@5=0.319867\n",
      "Completed training the SVD model in 193 seconds\n",
      "HR@20@5=0.569205, NDCG@20@5=0.324064\n"
     ]
    }
   ],
   "source": [
    "for nn in [0,1,2,3,4,5]:\n",
    "    ds1m = DataSet_1M(negNum=nn)\n",
    "    trainset = ds1m.trainset\n",
    "    testset = ds1m.testset\n",
    "    reader = sp.Reader(rating_scale=(0, 5))\n",
    "    spdata = sp.Dataset.load_from_df(pd.DataFrame(trainset),reader)\n",
    "    trainset_svd = spdata.build_full_trainset()\n",
    "    for k in [5,10,15,20]:#iterations epoches\n",
    "        algo = sp.SVD(n_factors=k, n_epochs=20, lr_all=0.001, reg_all=0.01 )#\n",
    "        tstart = time.time()\n",
    "        algo.fit(trainset_svd)\n",
    "        elapsed = time.time() - tstart    \n",
    "        print('Completed training the SVD model in %d seconds' % int(elapsed))\n",
    "        predictions = algo.test(testset)#testset include one positive and 99 negtive sample of every user.\n",
    "        user_iid_true_est = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            user_iid_true_est[uid].append((iid, true_r, est))\n",
    "        hits = []\n",
    "        ndcgs = []\n",
    "        for uid, iid_ratings in user_iid_true_est.items():\n",
    "            # Sort user ratings by estimated value\n",
    "            #iid_ratings.sort(key=lambda x: x[2], reverse=True) #sorted by est\n",
    "            scorelist = []\n",
    "            positem = -1\n",
    "            for iid, ture_r, est in iid_ratings:\n",
    "                if positem == -1: positem=iid #one positive item in first\n",
    "                scorelist.append([iid,est])\n",
    "            map_item_score = {}\n",
    "            for item, rate in scorelist: #turn dict\n",
    "                map_item_score[item] = rate\n",
    "            ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)#default Topn=10\n",
    "            hr = getHitRatio(ranklist, positem)\n",
    "            hits.append(hr)\n",
    "            ndcg = getNDCG(ranklist, positem)\n",
    "            ndcgs.append(ndcg)\n",
    "        hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "        print (\"HR@%d@%d=%.6f, NDCG@%d@%d=%.6f\" % (k, nn, hitratio, k, nn, ndcg))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. BMF: Bayesian Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 994169\n",
      "The length of Testset: 604000\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@5@0=0.217881, NDCG@5@0=0.115555\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@10@0=0.201821, NDCG@10@0=0.105868\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@15@0=0.242715, NDCG@15@0=0.130422\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@20@0=0.252152, NDCG@20@0=0.131339\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 1988338\n",
      "The length of Testset: 604000\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@5@1=0.237748, NDCG@5@1=0.125895\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@10@1=0.247351, NDCG@10@1=0.135720\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@15@1=0.233609, NDCG@15@1=0.122714\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@20@1=0.224172, NDCG@20@1=0.119261\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 2982507\n",
      "The length of Testset: 604000\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@5@2=0.219371, NDCG@5@2=0.114174\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@10@2=0.256457, NDCG@10@2=0.136222\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@15@2=0.246523, NDCG@15@2=0.135592\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@20@2=0.231954, NDCG@20@2=0.121909\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 3976676\n",
      "The length of Testset: 604000\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@5@3=0.211093, NDCG@5@3=0.111141\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@10@3=0.200662, NDCG@10@3=0.107045\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@15@3=0.229967, NDCG@15@3=0.122673\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@20@3=0.238742, NDCG@20@3=0.127750\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 4970845\n",
      "The length of Testset: 604000\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@5@4=0.234106, NDCG@5@4=0.124462\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@10@4=0.229139, NDCG@10@4=0.120417\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@15@4=0.218377, NDCG@15@4=0.118842\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@20@4=0.222185, NDCG@20@4=0.117755\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3706\n",
      "\tData Size: 994169\n",
      "\tSparsity: 0.04441379291858915\n",
      "The length of Trainset: 5965014\n",
      "The length of Testset: 604000\n",
      "Completed training the BMF model in 3 seconds\n",
      "HR@5@5=0.237086, NDCG@5@5=0.126940\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@10@5=0.212914, NDCG@10@5=0.112644\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@15@5=0.245199, NDCG@15@5=0.128647\n",
      "Completed training the BMF model in 2 seconds\n",
      "HR@20@5=0.229139, NDCG@20@5=0.121771\n"
     ]
    }
   ],
   "source": [
    "class BayesianMatrixFactorization():\n",
    "    \"\"\"\n",
    "    Bayesian Matrix Factorization model\n",
    "    R = PxQ\n",
    "    p ~ N(p|0, alpha^(-1)I)\n",
    "    q ~ N(q|0, alpha^(-1)I)\n",
    "    r = p @ q\n",
    "    t ~ N(r|p @ q, beta^(-1))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha_p:float=1., alpha_q:float=1., beta:float=1.):\n",
    "        \"\"\"\n",
    "        ----------\n",
    "        n_u, n_i: the number of users and items, respectively.\n",
    "        k : the number of latent factors\n",
    "        \"\"\"\n",
    "        self.alpha_p = alpha_p\n",
    "        self.alpha_q = alpha_q\n",
    "        self.beta = beta\n",
    "        #posterior of p,q \n",
    "        self.pos_mean_p = None\n",
    "        self.pos_precision_p = None\n",
    "        self.pos_mean_q = None\n",
    "        self.pos_precision_q = None\n",
    "\n",
    "    def fit(self, R:np.ndarray, k:int=5):\n",
    "        \"\"\"\n",
    "        bayesian update of parameters given training dataset\n",
    "        Parameters\n",
    "        ----------\n",
    "        R : (u,i) np.ndarray\n",
    "            training data independent variable, u is the number of users, i is the number of items.\n",
    "        k : int, the number of latent factors.\n",
    "        \"\"\"\n",
    "        #1. generate matrices P, Q\n",
    "        P = np.random.normal(0,self.alpha_p,(R.shape[0],k))#uxk\n",
    "        Q = np.random.normal(0,self.alpha_q,(R.shape[1],k))#ixk\n",
    "        #2.calculate the posterior with analytical solution\n",
    "        self.pos_precision_p = self.alpha_p + self.beta * Q @ Q.T # ixi\n",
    "        self.pos_mean_p = self.beta * R @ np.linalg.inv(self.pos_precision_p) @ Q # uxi,ixi,ixk -> uxk\n",
    "        self.pos_precision_q = self.alpha_q + self.beta * P @ P.T # uxu\n",
    "        self.pos_mean_q = self.beta * R.T @ np.linalg.inv(self.pos_precision_q) @ P # ixu,uxu,uxk -> ixk\n",
    "\n",
    "    def predict(self, sample_size:int=None):\n",
    "        \"\"\"\n",
    "        return mean  of predictive distribution\n",
    "        Parameters\n",
    "        ----------\n",
    "        sample_size : int, optional\n",
    "            number of samples to draw from the predictive distribution\n",
    "            (the default is None, no sampling from the distribution)\n",
    "        Returns\n",
    "        -------\n",
    "        R_pred : (u,i) np.ndarray\n",
    "            mean of the predictive distribution\n",
    "        R_pred_sample : (u,i,sample_size) np.ndarray\n",
    "            samples from the predictive distribution\n",
    "        \"\"\"\n",
    "        if sample_size is not None:\n",
    "            p_sample = np.random.multivariate_normal(self.pos_mean_p, np.linalg.inv(self.pos_precision_q), size=sample_size)\n",
    "            q_sample = np.random.multivariate_normal(self.pos_mean_q, np.linalg.inv(self.pos_precision_p), size=sample_size)\n",
    "            R_pred_sample_list=[]\n",
    "            for i in range(sample_size): \n",
    "                R_pred_sample_list.append( np.dot(p_sample, q_sample.T) )\n",
    "            R_pred_sample = np.mean(np.array(R_pred_sample_list), axis=0)\n",
    "            return  R_pred_sample #uxi\n",
    "        \n",
    "        R_pred = self.pos_mean_p @ self.pos_mean_q.T #R = PxQ\n",
    "        return R_pred #uxi\n",
    "    \n",
    "for nn in [0,1,2,3,4,5]:\n",
    "    ds1m = DataSet_1M(negNum=nn)\n",
    "    trainMat = ds1m.trainMat\n",
    "    testset = ds1m.testset\n",
    "    shape = ds1m.shape\n",
    "    for k in [5,10,15,20]:#iterations epoches\n",
    "        bmf = BayesianMatrixFactorization()\n",
    "        tstart = time.time()\n",
    "        bmf.fit(R=trainMat, k=k)\n",
    "        elapsed = time.time() - tstart    \n",
    "        print('Completed training the BMF model in %d seconds' % int(elapsed))\n",
    "        R_pred = bmf.predict()\n",
    "        hits = []\n",
    "        ndcgs = []\n",
    "        for c in range(0,shape[0]):#6040\n",
    "            scorelist = []\n",
    "            gtItem = -1\n",
    "            for u,i,r in testset[c*100:(c+1)*100]:#604000\n",
    "                if r == 1.0: gtItem = i\n",
    "                est = R_pred[int(u)][int(i)]\n",
    "                scorelist.append([i,est])\n",
    "            map_item_score = {}\n",
    "            for item, rate in scorelist: #turn dict\n",
    "                map_item_score[item] = rate\n",
    "            ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)#topn=10\n",
    "            hr = getHitRatio(ranklist, gtItem)\n",
    "            hits.append(hr)\n",
    "            ndcg = getNDCG(ranklist, gtItem)\n",
    "            ndcgs.append(ndcg)\n",
    "        hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "        print (\"HR@%d@%d=%.6f, NDCG@%d@%d=%.6f\" % (k, nn, hitratio, k, nn, ndcg))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset without negative sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import heapq\n",
    "import math\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import surprise as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 0.0444\n",
      "The length of Testset: 604000\n"
     ]
    }
   ],
   "source": [
    "#trainset\n",
    "filePath = \"/data/fjsdata/BNMF/ml-1m.train.rating\" \n",
    "data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "#data['rating']=data['rating'].apply(lambda x: 1.0 if float(x)>0.0 else 0.0)\n",
    "maxu, maxi = data['user'].max()+1, data['item'].max()+1\n",
    "print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "trainset = data.values.tolist()\n",
    "trainMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "for u,i,r in trainset:\n",
    "    trainMat[int(u)][int(i)] = float(r)\n",
    "#testset\n",
    "testset = []\n",
    "filePath = \"/data/fjsdata/BNMF/ml-1m.test.negative\" \n",
    "with open(filePath, 'r') as fd:\n",
    "    line = fd.readline()\n",
    "    while line != None and line != '':\n",
    "        arr = line.split('\\t')\n",
    "        u = eval(arr[0])[0]\n",
    "        testset.append([u, eval(arr[0])[1], 1.0])#first is one postive item\n",
    "        for i in arr[1:]:\n",
    "            testset.append([u, int(i), 0.0]) #99 negative items\n",
    "        line = fd.readline()\n",
    "print ('The length of Testset: %d'%(len(testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Baselien: SVD with scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@5=0.259272, NDCG@5=0.127297\n",
      "HR@10=0.258609, NDCG@10=0.125978\n",
      "HR@15=0.259106, NDCG@15=0.126195\n",
      "HR@20=0.258775, NDCG@20=0.126813\n"
     ]
    }
   ],
   "source": [
    "reader = sp.Reader(rating_scale=(0, 5))\n",
    "spdata = sp.Dataset.load_from_df(data,reader)\n",
    "trainset_svd = spdata.build_full_trainset()\n",
    "for K in [5,10,15,20]:#iterations epoches\n",
    "    algo = sp.SVD(n_factors=K, n_epochs=20, lr_all=0.001, reg_all=0.01 )#\n",
    "    algo.fit(trainset_svd)\n",
    "    predictions = algo.test(testset)#testset include one positive and 99 negtive sample of every user.\n",
    "    user_iid_true_est = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_iid_true_est[uid].append((iid, true_r, est))\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    for uid, iid_ratings in user_iid_true_est.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        #iid_ratings.sort(key=lambda x: x[2], reverse=True) #sorted by est\n",
    "        scorelist = []\n",
    "        positem = -1\n",
    "        for iid, ture_r, est in iid_ratings:\n",
    "            if positem == -1: positem=iid #one positive item in first\n",
    "            scorelist.append([iid,est])\n",
    "        map_item_score = {}\n",
    "        for item, rate in scorelist: #turn dict\n",
    "            map_item_score[item] = rate\n",
    "        ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)#default Topn=10\n",
    "        hr = getHitRatio(ranklist, positem)\n",
    "        hits.append(hr)\n",
    "        ndcg = getNDCG(ranklist, positem)\n",
    "        ndcgs.append(ndcg)\n",
    "    hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "    print (\"HR@%d=%.6f, NDCG@%d=%.6f\" % (K, hitratio, K, ndcg))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. BMF: Bayesian Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@5=0.424338, NDCG@5=0.166753\n",
      "HR@10=0.409934, NDCG@10=0.160615\n",
      "HR@15=0.424172, NDCG@15=0.173028\n",
      "HR@20=0.413576, NDCG@20=0.162718\n"
     ]
    }
   ],
   "source": [
    "class BayesianMatrixFactorization():\n",
    "    \"\"\"\n",
    "    Bayesian Matrix Factorization model\n",
    "    R = PxQ\n",
    "    p ~ N(p|0, alpha^(-1)I)\n",
    "    q ~ N(q|0, alpha^(-1)I)\n",
    "    r = p @ q\n",
    "    t ~ N(r|p @ q, beta^(-1))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha_p:float=1., alpha_q:float=1., beta:float=1.):\n",
    "        \"\"\"\n",
    "        ----------\n",
    "        n_u, n_i: the number of users and items, respectively.\n",
    "        k : the number of latent factors\n",
    "        \"\"\"\n",
    "        self.alpha_p = alpha_p\n",
    "        self.alpha_q = alpha_q\n",
    "        self.beta = beta\n",
    "        #posterior of p,q \n",
    "        self.pos_mean_p = None\n",
    "        self.pos_precision_p = None\n",
    "        self.pos_mean_q = None\n",
    "        self.pos_precision_q = None\n",
    "\n",
    "    def fit(self, R:np.ndarray, k:int=5):\n",
    "        \"\"\"\n",
    "        bayesian update of parameters given training dataset\n",
    "        Parameters\n",
    "        ----------\n",
    "        R : (u,i) np.ndarray\n",
    "            training data independent variable, u is the number of users, i is the number of items.\n",
    "        k : int, the number of latent factors.\n",
    "        \"\"\"\n",
    "        #1. generate matrices P, Q\n",
    "        P = np.random.normal(0,self.alpha_p,(R.shape[0],k))#uxk\n",
    "        Q = np.random.normal(0,self.alpha_q,(R.shape[1],k))#ixk\n",
    "        #2.calculate the posterior with analytical solution\n",
    "        self.pos_precision_p = self.alpha_p + self.beta * Q @ Q.T # ixi\n",
    "        self.pos_mean_p = self.beta * R @ np.linalg.inv(self.pos_precision_p) @ Q # uxi,ixi,ixk -> uxk\n",
    "        self.pos_precision_q = self.alpha_q + self.beta * P @ P.T # uxu\n",
    "        self.pos_mean_q = self.beta * R.T @ np.linalg.inv(self.pos_precision_q) @ P # ixu,uxu,uxk -> ixk\n",
    "\n",
    "    def predict(self, sample_size:int=None):\n",
    "        \"\"\"\n",
    "        return mean  of predictive distribution\n",
    "        Parameters\n",
    "        ----------\n",
    "        sample_size : int, optional\n",
    "            number of samples to draw from the predictive distribution\n",
    "            (the default is None, no sampling from the distribution)\n",
    "        Returns\n",
    "        -------\n",
    "        R_pred : (u,i) np.ndarray\n",
    "            mean of the predictive distribution\n",
    "        R_pred_sample : (u,i,sample_size) np.ndarray\n",
    "            samples from the predictive distribution\n",
    "        \"\"\"\n",
    "        if sample_size is not None:\n",
    "            p_sample = np.random.multivariate_normal(self.pos_mean_p, np.linalg.inv(self.pos_precision_q), size=sample_size)\n",
    "            q_sample = np.random.multivariate_normal(self.pos_mean_q, np.linalg.inv(self.pos_precision_p), size=sample_size)\n",
    "            R_pred_sample_list=[]\n",
    "            for i in range(sample_size): \n",
    "                R_pred_sample_list.append( np.dot(p_sample, q_sample.T) )\n",
    "            R_pred_sample = np.mean(np.array(R_pred_sample_list), axis=0)\n",
    "            return  R_pred_sample #uxi\n",
    "        \n",
    "        R_pred = self.pos_mean_p @ self.pos_mean_q.T #R = PxQ\n",
    "        return R_pred #uxi\n",
    "\n",
    "\n",
    "for K in [5,10,15,20]:#iterations epoches\n",
    "    bmf = BayesianMatrixFactorization()\n",
    "    bmf.fit(R=trainMat, k=K)\n",
    "    R_pred = bmf.predict()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    for c in range(0,maxu):#6040\n",
    "        scorelist = []\n",
    "        gtItem = -1\n",
    "        for u,i,r in testset[c*100:(c+1)*100]:#604000\n",
    "            if r == 1.0: gtItem = i\n",
    "            est = R_pred[int(u)][int(i)]\n",
    "            scorelist.append([i,est])\n",
    "        map_item_score = {}\n",
    "        for item, rate in scorelist: #turn dict\n",
    "            map_item_score[item] = rate\n",
    "        ranklist = heapq.nlargest(30, map_item_score, key=map_item_score.get)#topn=20\n",
    "        hr = getHitRatio(ranklist, gtItem)\n",
    "        hits.append(hr)\n",
    "        ndcg = getNDCG(ranklist, gtItem)\n",
    "        ndcgs.append(ndcg)\n",
    "    hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "    print (\"HR@%d=%.6f, NDCG@%d=%.6f\" % (K, hitratio, K, ndcg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

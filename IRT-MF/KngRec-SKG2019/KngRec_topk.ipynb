{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is:2547452 rows and 3 columns\n",
      "  K                RMSE\n",
      "RMSE: 0.0535\n",
      " 50          0.05348533\n",
      "RMSE: 0.0537\n",
      "100          0.05373604\n",
      "RMSE: 0.0540\n",
      "200          0.05395298\n",
      "RMSE: 0.0523\n",
      "500          0.05226371\n"
     ]
    }
   ],
   "source": [
    "import surprise as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)\n",
    "kbdata = kbdata.loc[(kbdata['num']<200)]#seven months, one per day\n",
    "num_max=kbdata['num'].max()\n",
    "num_min=kbdata['num'].min()\n",
    "kbdata['num']=kbdata['num'].apply(lambda x: (x-num_min+1)*1.0/(num_max-num_min+1) )\n",
    "print ('Dataset shape is:%d rows and %d columns'%(kbdata.shape[0],kbdata.shape[1]))\n",
    "\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'num']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "print (\"%3s%20s\" % ('K','RMSE'))\n",
    "for k in [50,100,200,500]:\n",
    "    #3.Training the model and predicting ratings for the testset\n",
    "    algo = sp.SVD(n_factors=k)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "    #4.rating prediction\n",
    "    RMSE = sp.accuracy.rmse(predictions)\n",
    "    print (\"%3s%20.8f\" % (k, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is:2547452 rows and 3 columns\n",
      "  K                RMSE\n",
      "RMSE: 0.0567\n",
      " 50          0.05672902\n",
      "RMSE: 0.0567\n",
      "100          0.05671787\n",
      "RMSE: 0.0567\n",
      "200          0.05674449\n",
      "RMSE: 0.0569\n",
      "500          0.05686118\n"
     ]
    }
   ],
   "source": [
    "import surprise as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)\n",
    "kbdata = kbdata.loc[(kbdata['num']<200)]#seven months, one per day\n",
    "num_max=kbdata['num'].max()\n",
    "num_min=kbdata['num'].min()\n",
    "kbdata['num']=kbdata['num'].apply(lambda x: (x-num_min+1)*1.0/(num_max-num_min+1) )\n",
    "print ('Dataset shape is:%d rows and %d columns'%(kbdata.shape[0],kbdata.shape[1]))\n",
    "\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'num']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "print (\"%3s%20s\" % ('K','RMSE'))\n",
    "for k in [50,100,200,500]:\n",
    "    #3.Training the model and predicting ratings for the testset\n",
    "    algo = sp.NMF(n_factors=k)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "    #4.rating prediction\n",
    "    RMSE = sp.accuracy.rmse(predictions)\n",
    "    print (\"%3s%20.8f\" % (k, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is:2547452 rows and 3 columns\n",
      "  K                RMSE\n",
      "RMSE: 0.0536\n",
      " 50          0.05359890\n",
      "RMSE: 0.0533\n",
      "100          0.05332163\n",
      "RMSE: 0.0528\n",
      "200          0.05276875\n"
     ]
    }
   ],
   "source": [
    "import surprise as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)\n",
    "kbdata = kbdata.loc[(kbdata['num']<200)]#seven months, one per day\n",
    "num_max=kbdata['num'].max()\n",
    "num_min=kbdata['num'].min()\n",
    "kbdata['num']=kbdata['num'].apply(lambda x: (x-num_min+1)*1.0/(num_max-num_min+1) )\n",
    "print ('Dataset shape is:%d rows and %d columns'%(kbdata.shape[0],kbdata.shape[1]))\n",
    "\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'num']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "print (\"%3s%20s\" % ('K','RMSE'))\n",
    "for k in [50,100,200,500]:\n",
    "    #3.Training the model and predicting ratings for the testset\n",
    "    algo = sp.SVDpp(n_factors=k)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "    #4.rating prediction\n",
    "    RMSE = sp.accuracy.rmse(predictions)\n",
    "    print (\"%3s%20.8f\" % (k, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)\n",
    "#seven month multiply thirty days per month is equal to 210,and one time per day multiply 210 is 210.\n",
    "kbdata = kbdata.loc[(kbdata['num']<200)]\n",
    "print ('Dataset shape is:%d rows and %d columns'%(kbdata.shape[0],kbdata.shape[1]))\n",
    "\n",
    "#2.Calculating the mean of CSRs and KEs.\n",
    "Ab_csr = kbdata['num'].groupby(kbdata['csr']).mean()#the type of groupby is Series\n",
    "Di_ke = kbdata['num'].groupby(kbdata['ke']).mean()\n",
    "#3.Calculating the IRT of every pair<csr,ke> which is the pdf of norm\n",
    "#mu=Di_ke,sigma=Ab_csr\n",
    "#x[2]=num,x[1]=ke,x[0]=csr\n",
    "kbdata['irt'] = kbdata.apply(lambda x: \"{:.8f}\".format(stats.norm.pdf(int(x[2]), Di_ke[int(x[1])], Ab_csr[int(x[0])])),axis=1)\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "print (\"%3s%20s\" % ('K','RMSE'))\n",
    "for k in [50,100,200,500]:\n",
    "    #3.Training the model and predicting ratings for the testset\n",
    "    algo = sp.SVD(n_factors=k)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "    #4.rating prediction\n",
    "    RMSE = sp.accuracy.rmse(predictions)\n",
    "    print (\"%3s%20.8f\" % (k, RMSE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is:2547452 rows and 3 columns\n",
      "    csr     ke  num         irt\n",
      "0  2986  42211    1  0.09717266\n",
      "1  2986  28115    2  0.00000000\n",
      "2  2986  29249    8  0.00142802\n",
      "3  2986  75667    1  0.19368211\n",
      "4  2986  74903    1  0.17465533\n"
     ]
    }
   ],
   "source": [
    "import surprise as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)\n",
    "#seven month multiply thirty days per month is equal to 210,and one time per day multiply 210 is 210.\n",
    "kbdata = kbdata.loc[(kbdata['num']<200)]\n",
    "print ('Dataset shape is:%d rows and %d columns'%(kbdata.shape[0],kbdata.shape[1]))\n",
    "\n",
    "#2.Calculating the mean of CSRs and KEs.\n",
    "Ab_csr = kbdata['num'].groupby(kbdata['csr']).mean()#the type of groupby is Series\n",
    "Di_ke = kbdata['num'].groupby(kbdata['ke']).mean()\n",
    "#3.Calculating the IRT of every pair<csr,ke> which is the pdf of norm\n",
    "#mu=Di_ke,sigma=Ab_csr\n",
    "#x[2]=num,x[1]=ke,x[0]=csr\n",
    "kbdata['irt'] = kbdata.apply(lambda x: \"{:.8f}\".format(stats.norm.pdf(int(x[2]), Di_ke[int(x[1])], Ab_csr[int(x[0])])),axis=1)\n",
    "print (kbdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  K          Precisions             Recalls                NDCG\n",
      "  5          0.64534554          0.54452437          0.93450164\n",
      " 10          0.63577434          0.59990276          0.93442357\n",
      " 15          0.62920554          0.63537925          0.93470233\n",
      " 20          0.62379936          0.66120616          0.93491894\n"
     ]
    }
   ],
   "source": [
    "#SVD,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.SVD()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by precision, recall and  NDCG\n",
    "#print ('RMSE of testset is:%.8f'%(sp.accuracy.rmse(predictions)))\n",
    "def calc_dcg(items):\n",
    "    dcg = 0\n",
    "    i = 0\n",
    "    for item in items:\n",
    "        i += 1\n",
    "        dcg += (math.pow(2, item) - 1)/ math.log(1 + i, 2)\n",
    "    return dcg\n",
    "def index_at_k(predictions, k, threshold=0.1):\n",
    "   #Return precision and recall at k metrics for each user.\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    ndcgs =dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r > threshold) for (_, true_r) in user_ratings)\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est > threshold) for (est, _) in user_ratings[:k])\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r > threshold) and (est > threshold)) for (est, true_r) in user_ratings[:k])\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "        #true ratings of recommended items in top k\n",
    "        l_rec_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        dcg = calc_dcg(l_rec_k)\n",
    "        #l_rec_k.sort(reverse=True)\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        l_rel_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        idcg = calc_dcg(l_rel_k)\n",
    "        if (idcg==0):idcg = 1\n",
    "        ndcgs[uid]=dcg*1.0/idcg\n",
    "    return precisions, recalls, ndcgs\n",
    "\n",
    "print (\"%3s%20s%20s%20s\" % ('K','Precisions','Recalls','NDCG'))\n",
    "for k in [5,10,15,20]:#latent factor\n",
    "    precisions, recalls, ndcgs = index_at_k(predictions, k=k)\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    ndcg = sum(ndcg for ndcg in ndcgs.values()) / len(ndcgs)\n",
    "    print (\"%3s%20.8f%20.8f%20.8f\" % (k, precision, recall, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  K          Precisions             Recalls                NDCG\n",
      "  5          0.97780279          0.20617431          0.93414137\n",
      " 10          0.96902750          0.27575618          0.93380992\n",
      " 15          0.96274146          0.32310532          0.93377836\n",
      " 20          0.95811974          0.36025142          0.93437106\n"
     ]
    }
   ],
   "source": [
    "#SVD,threshold=0.0\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.SVD()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by precision, recall and  NDCG\n",
    "#print ('RMSE of testset is:%.8f'%(sp.accuracy.rmse(predictions)))\n",
    "def calc_dcg(items):\n",
    "    dcg = 0\n",
    "    i = 0\n",
    "    for item in items:\n",
    "        i += 1\n",
    "        dcg += (math.pow(2, item) - 1)/ math.log(1 + i, 2)\n",
    "    return dcg\n",
    "def index_at_k(predictions, k, threshold=0.0):\n",
    "   #Return precision and recall at k metrics for each user.\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    ndcgs =dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r > threshold) for (_, true_r) in user_ratings)\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est > threshold) for (est, _) in user_ratings[:k])\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r > threshold) and (est > threshold)) for (est, true_r) in user_ratings[:k])\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "        #true ratings of recommended items in top k\n",
    "        l_rec_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        dcg = calc_dcg(l_rec_k)\n",
    "        #l_rec_k.sort(reverse=True)\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        l_rel_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        idcg = calc_dcg(l_rel_k)\n",
    "        if (idcg==0):idcg = 1\n",
    "        ndcgs[uid]=dcg*1.0/idcg\n",
    "    return precisions, recalls, ndcgs\n",
    "\n",
    "print (\"%3s%20s%20s%20s\" % ('K','Precisions','Recalls','NDCG'))\n",
    "for k in [5,10,15,20]:#latent factor\n",
    "    precisions, recalls, ndcgs = index_at_k(predictions, k=k)\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    ndcg = sum(ndcg for ndcg in ndcgs.values()) / len(ndcgs)\n",
    "    print (\"%3s%20.8f%20.8f%20.8f\" % (k, precision, recall, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  K          Precisions             Recalls                NDCG\n",
      "  5          0.99660174          0.48006813          0.96399688\n",
      " 10          0.99528075          0.50263986          0.96371162\n",
      " 15          0.99460948          0.51505572          0.96331910\n",
      " 20          0.99412368          0.52267691          0.96314211\n"
     ]
    }
   ],
   "source": [
    "#NMF,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.NMF()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by precision, recall and  NDCG\n",
    "#print ('RMSE of testset is:%.8f'%(sp.accuracy.rmse(predictions)))\n",
    "def calc_dcg(items):\n",
    "    dcg = 0\n",
    "    i = 0\n",
    "    for item in items:\n",
    "        i += 1\n",
    "        dcg += (math.pow(2, item) - 1)/ math.log(1 + i, 2)\n",
    "    return dcg\n",
    "def index_at_k(predictions, k, threshold=0.1):\n",
    "   #Return precision and recall at k metrics for each user.\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    ndcgs =dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r > threshold) for (_, true_r) in user_ratings)\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est > threshold) for (est, _) in user_ratings[:k])\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r > threshold) and (est > threshold)) for (est, true_r) in user_ratings[:k])\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "        #true ratings of recommended items in top k\n",
    "        l_rec_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        dcg = calc_dcg(l_rec_k)\n",
    "        #l_rec_k.sort(reverse=True)\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        l_rel_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        idcg = calc_dcg(l_rel_k)\n",
    "        if (idcg==0):idcg = 1\n",
    "        ndcgs[uid]=dcg*1.0/idcg\n",
    "    return precisions, recalls, ndcgs\n",
    "\n",
    "print (\"%3s%20s%20s%20s\" % ('K','Precisions','Recalls','NDCG'))\n",
    "for k in [5,10,15,20]:#latent factor\n",
    "    precisions, recalls, ndcgs = index_at_k(predictions, k=k)\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    ndcg = sum(ndcg for ndcg in ndcgs.values()) / len(ndcgs)\n",
    "    print (\"%3s%20.8f%20.8f%20.8f\" % (k, precision, recall, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  K          Precisions             Recalls                NDCG\n",
      "  5          0.78529268          0.55549431          0.95665176\n",
      " 10          0.77957600          0.61425370          0.95737474\n",
      " 15          0.77606672          0.65202463          0.95785396\n",
      " 20          0.77332110          0.67972914          0.95844873\n"
     ]
    }
   ],
   "source": [
    "#KNN,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.KNNWithMeans()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by precision, recall and  NDCG\n",
    "#print ('RMSE of testset is:%.8f'%(sp.accuracy.rmse(predictions)))\n",
    "def calc_dcg(items):\n",
    "    dcg = 0\n",
    "    i = 0\n",
    "    for item in items:\n",
    "        i += 1\n",
    "        dcg += (math.pow(2, item) - 1)/ math.log(1 + i, 2)\n",
    "    return dcg\n",
    "def index_at_k(predictions, k, threshold=0.1):\n",
    "   #Return precision and recall at k metrics for each user.\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    ndcgs =dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r > threshold) for (_, true_r) in user_ratings)\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est > threshold) for (est, _) in user_ratings[:k])\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r > threshold) and (est > threshold)) for (est, true_r) in user_ratings[:k])\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "        #true ratings of recommended items in top k\n",
    "        l_rec_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        dcg = calc_dcg(l_rec_k)\n",
    "        #l_rec_k.sort(reverse=True)\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        l_rel_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        idcg = calc_dcg(l_rel_k)\n",
    "        if (idcg==0):idcg = 1\n",
    "        ndcgs[uid]=dcg*1.0/idcg\n",
    "    return precisions, recalls, ndcgs\n",
    "\n",
    "print (\"%3s%20s%20s%20s\" % ('K','Precisions','Recalls','NDCG'))\n",
    "for k in [5,10,15,20]:#latent factor\n",
    "    precisions, recalls, ndcgs = index_at_k(predictions, k=k)\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    ndcg = sum(ndcg for ndcg in ndcgs.values()) / len(ndcgs)\n",
    "    print (\"%3s%20.8f%20.8f%20.8f\" % (k, precision, recall, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  K          Precisions             Recalls                NDCG\n",
      "  5          1.00000000          0.37979640          0.46956242\n",
      " 10          1.00000000          0.37979640          0.50726660\n",
      " 15          1.00000000          0.37979640          0.53147843\n",
      " 20          1.00000000          0.37979640          0.54965492\n"
     ]
    }
   ],
   "source": [
    "#CoClustering,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.CoClustering()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by precision, recall and  NDCG\n",
    "#print ('RMSE of testset is:%.8f'%(sp.accuracy.rmse(predictions)))\n",
    "def calc_dcg(items):\n",
    "    dcg = 0\n",
    "    i = 0\n",
    "    for item in items:\n",
    "        i += 1\n",
    "        dcg += (math.pow(2, item) - 1)/ math.log(1 + i, 2)\n",
    "    return dcg\n",
    "def index_at_k(predictions, k, threshold=0.1):\n",
    "   #Return precision and recall at k metrics for each user.\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    ndcgs =dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r > threshold) for (_, true_r) in user_ratings)\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est > threshold) for (est, _) in user_ratings[:k])\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r > threshold) and (est > threshold)) for (est, true_r) in user_ratings[:k])\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "        #true ratings of recommended items in top k\n",
    "        l_rec_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        dcg = calc_dcg(l_rec_k)\n",
    "        #l_rec_k.sort(reverse=True)\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        l_rel_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        idcg = calc_dcg(l_rel_k)\n",
    "        if (idcg==0):idcg = 1\n",
    "        ndcgs[uid]=dcg*1.0/idcg\n",
    "    return precisions, recalls, ndcgs\n",
    "\n",
    "print (\"%3s%20s%20s%20s\" % ('K','Precisions','Recalls','NDCG'))\n",
    "for k in [5,10,15,20]:#latent factor\n",
    "    precisions, recalls, ndcgs = index_at_k(predictions, k=k)\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    ndcg = sum(ndcg for ndcg in ndcgs.values()) / len(ndcgs)\n",
    "    print (\"%3s%20.8f%20.8f%20.8f\" % (k, precision, recall, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  K          Precisions             Recalls                NDCG\n",
      "  5          0.74363254          0.55374854          0.95189569\n",
      " 10          0.73540521          0.61457554          0.95193570\n",
      " 15          0.72944207          0.65349744          0.95254446\n",
      " 20          0.72477783          0.68205860          0.95303638\n"
     ]
    }
   ],
   "source": [
    "#SVDPP,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.SVDpp()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by precision, recall and  NDCG\n",
    "#print ('RMSE of testset is:%.8f'%(sp.accuracy.rmse(predictions)))\n",
    "def calc_dcg(items):\n",
    "    dcg = 0\n",
    "    i = 0\n",
    "    for item in items:\n",
    "        i += 1\n",
    "        dcg += (math.pow(2, item) - 1)/ math.log(1 + i, 2)\n",
    "    return dcg\n",
    "def index_at_k(predictions, k, threshold=0.1):\n",
    "   #Return precision and recall at k metrics for each user.\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    ndcgs =dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r > threshold) for (_, true_r) in user_ratings)\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est > threshold) for (est, _) in user_ratings[:k])\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r > threshold) and (est > threshold)) for (est, true_r) in user_ratings[:k])\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "        #true ratings of recommended items in top k\n",
    "        l_rec_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        dcg = calc_dcg(l_rec_k)\n",
    "        #l_rec_k.sort(reverse=True)\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        l_rel_k = [true_r for (_,true_r) in user_ratings[:k]]\n",
    "        idcg = calc_dcg(l_rel_k)\n",
    "        if (idcg==0):idcg = 1\n",
    "        ndcgs[uid]=dcg*1.0/idcg\n",
    "    return precisions, recalls, ndcgs\n",
    "\n",
    "print (\"%3s%20s%20s%20s\" % ('K','Precisions','Recalls','NDCG'))\n",
    "for k in [5,10,15,20]:#latent factor\n",
    "    precisions, recalls, ndcgs = index_at_k(predictions, k=k)\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    ndcg = sum(ndcg for ndcg in ndcgs.values()) / len(ndcgs)\n",
    "    print (\"%3s%20.8f%20.8f%20.8f\" % (k, precision, recall, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Problem occurred during compilation with the command line below:\n",
      "/usr/bin/g++ -shared -g -O3 -fno-math-errno -Wno-unused-label -Wno-unused-variable -Wno-write-strings -march=broadwell -mmmx -mno-3dnow -msse -msse2 -msse3 -mssse3 -mno-sse4a -mcx16 -msahf -mmovbe -maes -mno-sha -mpclmul -mpopcnt -mabm -mno-lwp -mfma -mno-fma4 -mno-xop -mbmi -mbmi2 -mno-tbm -mavx -mavx2 -msse4.2 -msse4.1 -mlzcnt -mrtm -mhle -mrdrnd -mf16c -mfsgsbase -mrdseed -mprfchw -madx -mfxsr -mxsave -mxsaveopt -mno-avx512f -mno-avx512er -mno-avx512cd -mno-avx512pf -mno-prefetchwt1 -mno-clflushopt -mno-xsavec -mno-xsaves -mno-avx512dq -mno-avx512bw -mno-avx512vl -mno-avx512ifma -mno-avx512vbmi -mno-clwb -mno-pcommit -mno-mwaitx --param l1-cache-size=32 --param l1-cache-line-size=64 --param l2-cache-size=35840 -mtune=broadwell -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -I/usr/local/lib/python3.6/dist-packages/theano/gof/c_code -L/usr/lib -fvisibility=hidden -o /root/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-3.6.6-64/tmpaym1p1lj/m70542f94d0fa8294932bfe3e6e97b004f11825a71aac6bc9c5e16db40f088ccd.so /root/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-3.6.6-64/tmpaym1p1lj/mod.cpp -lpython3.6m\n",
      "ERROR (theano.gof.cmodule): [Errno 12] Cannot allocate memory\n",
      "2019-06-16 01:14:22 ERROR: [Errno 12] Cannot allocate memory\n",
      "[Errno 12] Cannot allocate memory\n",
      "[Errno 12] Cannot allocate memory\n",
      "[Errno 12] Cannot allocate memory\n",
      "[Errno 12] Cannot allocate memory\n",
      "[Errno 12] Cannot allocate memory\n",
      "[Errno 12] Cannot allocate memory\n",
      "[Errno 12] Cannot allocate memory\n",
      "[Errno 12] Cannot allocate memory\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a069df3c296e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mirt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeterministic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mirt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#Rasch model of irt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#3.后验分布计算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymc3/distributions/distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtotal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Name needs to be a string but got: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymc3/model.py\u001b[0m in \u001b[0;36mVar\u001b[0;34m(self, name, dist, data, total_size)\u001b[0m\n\u001b[1;32m    837\u001b[0m                 var = ObservedRV(name=name, data=data,\n\u001b[1;32m    838\u001b[0m                                  \u001b[0mdistribution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m                                  total_size=total_size, model=self)\n\u001b[0m\u001b[1;32m    840\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserved_RVs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymc3/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, type, owner, index, name, data, distribution, total_size, model)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             theano.gof.Apply(theano.compile.view_op,\n\u001b[1;32m   1335\u001b[0m                              inputs=[data], outputs=[self])\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;31m# compute output value once with test inputs to validate graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 thunk = node.op.make_thunk(node, storage_map, compute_map,\n\u001b[0;32m--> 670\u001b[0;31m                                            no_recycling=[])\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling, impl)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[0;32m--> 955\u001b[0;31m                                          no_recycling)\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0;31m# We requested the c code, so don't catch the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[0;32m--> 858\u001b[0;31m                                 output_storage=node_output_storage)\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1215\u001b[0m         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[1;32m   1216\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36m__compile__\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1155\u001b[0m                                             \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                                             \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m                                             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         return (thunk,\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcthunk_factory\u001b[0;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1622\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[0;32m-> 1624\u001b[0;31m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m         \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cmodule.py\u001b[0m in \u001b[0;36mmodule_from_key\u001b[0;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0mlib_dirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 \u001b[0mlibs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m                 preargs=preargs)\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/gof/cmodule.py\u001b[0m in \u001b[0;36mcompile_str\u001b[0;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)\u001b[0m\n\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2351\u001b[0;31m             \u001b[0mp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_subprocess_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2352\u001b[0m             \u001b[0mcompile_stderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/misc/windows.py\u001b[0m in \u001b[0;36moutput_subprocess_Popen\u001b[0;34m(command, **params)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stdout'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;31m# we need to use communicate to make sure we don't deadlock around\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# the stdout/stderr pipe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/misc/windows.py\u001b[0m in \u001b[0;36msubprocess_Popen\u001b[0;34m(command, **params)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstdin\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    707\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1273\u001b[0m                             \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m                             restore_signals, start_new_session, preexec_fn)\n\u001b[0m\u001b[1;32m   1276\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import pymc3 as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import theano.tensor as tt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)#iterator = True)\n",
    "#kbdata =kbdata.get_chunk(1000)\n",
    "#kbdata = kbdata.loc[(kbdata['num']<200)]#seven months, one per day\n",
    "kbdata['num'] = kbdata['num'].apply(lambda x:1)#assume that the csr have grasped the ke if he readed the ke one time.\n",
    "\n",
    "#2.constructing the probabilistic model\n",
    "uNum = len(kbdata['csr'].unique())#numbers of csr\n",
    "iNum = len(kbdata['ke'].unique())#numbers of ke\n",
    "UI = np.zeros((uNum, iNum))#turn into sparse matrix\n",
    "for index, row in kbdata.iterrows(): # get each line\n",
    "    UI[int(row['csr'])][int(row['ke'])] = row['num']\n",
    "Y_output = theano.shared(UI)#转numpy array\n",
    "with pm.Model() as IRT_model:\n",
    "    # Creating the model\n",
    "    Ab = pm.Normal('Ability', mu=0, sd=1, shape=(uNum,1)) #skill of csr\n",
    "    Di = pm.Normal('Difficulty', mu=0, sd=1, shape=(1,iNum))#difficulty of ke\n",
    "    irt = tt.dot(Ab,Di)\n",
    "    p = pm.Deterministic('p', pm.math.sigmoid(irt))#Rasch model of irt\n",
    "    Y = pm.Bernoulli('Y',p=p, observed=Y_output)\n",
    "    \n",
    "#3.后验分布计算  \n",
    "with IRT_model:        \n",
    "    #start=pm.find_MAP()  # 参数初猜\n",
    "    #step = pm.Metropolis()\n",
    "    #trace = pm.sample(100,start=start,step=step,chains=2,cores=8)\n",
    "    inference = pm.ADVI()\n",
    "    approx = pm.fit(n=1000, method=inference)\n",
    "    trace = approx.sample(draws=500)\n",
    "\n",
    "print (trace['Ability']) \n",
    "print (trace['Difficulty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 01:09:03 INFO: start loading data\n",
      "start loading data\n",
      "start loading data\n",
      "start loading data\n",
      "start loading data\n",
      "start loading data\n",
      "start loading data\n",
      "2019-06-17 01:09:03 INFO: data loaded\n",
      "data loaded\n",
      "data loaded\n",
      "data loaded\n",
      "data loaded\n",
      "data loaded\n",
      "data loaded\n",
      "100%|██████████| 2/2 [00:00<00:00, 358.00it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 449.96it/s]\n",
      "2019-06-17 01:09:03 DEBUG: E step runs for 546.763 sec\n",
      "E step runs for 546.763 sec\n",
      "E step runs for 546.763 sec\n",
      "E step runs for 546.763 sec\n",
      "E step runs for 546.763 sec\n",
      "E step runs for 546.763 sec\n",
      "E step runs for 546.763 sec\n",
      "100%|██████████| 2/2 [00:00<00:00, 161.33it/s]\n",
      "2019-06-17 01:09:04 DEBUG: M step runs for 282.779 sec\n",
      "M step runs for 282.779 sec\n",
      "M step runs for 282.779 sec\n",
      "M step runs for 282.779 sec\n",
      "M step runs for 282.779 sec\n",
      "M step runs for 282.779 sec\n",
      "M step runs for 282.779 sec\n",
      "2019-06-17 01:09:04 DEBUG: score calculating\n",
      "score calculating\n",
      "score calculating\n",
      "score calculating\n",
      "score calculating\n",
      "score calculating\n",
      "score calculating\n",
      "100%|██████████| 2/2 [00:00<00:00, 2695.57it/s]\n",
      "2019-06-17 01:09:04 DEBUG: score calculated.\n",
      "score calculated.\n",
      "score calculated.\n",
      "score calculated.\n",
      "score calculated.\n",
      "score calculated.\n",
      "score calculated.\n",
      "2019-06-17 01:09:04 DEBUG: 0.5000000000000001\n",
      "0.5000000000000001\n",
      "0.5000000000000001\n",
      "0.5000000000000001\n",
      "0.5000000000000001\n",
      "0.5000000000000001\n",
      "0.5000000000000001\n",
      "2019-06-17 01:09:04 DEBUG: stop condition runs for 160.026 sec\n",
      "stop condition runs for 160.026 sec\n",
      "stop condition runs for 160.026 sec\n",
      "stop condition runs for 160.026 sec\n",
      "stop condition runs for 160.026 sec\n",
      "stop condition runs for 160.026 sec\n",
      "stop condition runs for 160.026 sec\n",
      "100%|██████████| 2/2 [00:00<00:00, 390.49it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 455.65it/s]\n",
      "2019-06-17 01:09:04 DEBUG: E step runs for 529.388 sec\n",
      "E step runs for 529.388 sec\n",
      "E step runs for 529.388 sec\n",
      "E step runs for 529.388 sec\n",
      "E step runs for 529.388 sec\n",
      "E step runs for 529.388 sec\n",
      "E step runs for 529.388 sec\n",
      "100%|██████████| 2/2 [00:00<00:00, 239.13it/s]\n",
      "2019-06-17 01:09:05 DEBUG: M step runs for 272.838 sec\n",
      "M step runs for 272.838 sec\n",
      "M step runs for 272.838 sec\n",
      "M step runs for 272.838 sec\n",
      "M step runs for 272.838 sec\n",
      "M step runs for 272.838 sec\n",
      "M step runs for 272.838 sec\n",
      "2019-06-17 01:09:05 DEBUG: score calculating\n",
      "score calculating\n",
      "score calculating\n",
      "score calculating\n",
      "score calculating\n",
      "score calculating\n",
      "score calculating\n",
      "100%|██████████| 2/2 [00:00<00:00, 2338.61it/s]\n",
      "2019-06-17 01:09:05 DEBUG: score calculated.\n",
      "score calculated.\n",
      "score calculated.\n",
      "score calculated.\n",
      "score calculated.\n",
      "score calculated.\n",
      "score calculated.\n",
      "2019-06-17 01:09:05 DEBUG: 0.5000000000000001\n",
      "0.5000000000000001\n",
      "0.5000000000000001\n",
      "0.5000000000000001\n",
      "0.5000000000000001\n",
      "0.5000000000000001\n",
      "0.5000000000000001\n",
      "2019-06-17 01:09:05 INFO: EM converged at iteration 2.\n",
      "EM converged at iteration 2.\n",
      "EM converged at iteration 2.\n",
      "EM converged at iteration 2.\n",
      "EM converged at iteration 2.\n",
      "EM converged at iteration 2.\n",
      "EM converged at iteration 2.\n",
      "2019-06-17 01:09:05 DEBUG: stop condition runs for 175.471 sec\n",
      "stop condition runs for 175.471 sec\n",
      "stop condition runs for 175.471 sec\n",
      "stop condition runs for 175.471 sec\n",
      "stop condition runs for 175.471 sec\n",
      "stop condition runs for 175.471 sec\n",
      "stop condition runs for 175.471 sec\n",
      "2019-06-17 01:09:05 INFO: parameter estimated\n",
      "parameter estimated\n",
      "parameter estimated\n",
      "parameter estimated\n",
      "parameter estimated\n",
      "parameter estimated\n",
      "parameter estimated\n",
      "2019-06-17 01:09:05 INFO: parameter retrieved\n",
      "parameter retrieved\n",
      "parameter retrieved\n",
      "parameter retrieved\n",
      "parameter retrieved\n",
      "parameter retrieved\n",
      "parameter retrieved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'beta': -1.8612584399919198e-16, 'alpha': 0.25, 'c': 0.0}, 2: {'beta': -1.8612584399919198e-16, 'alpha': 0.25, 'c': 0.0}}\n",
      "{1: -1.700029006457271e-16, 2: -1.700029006457271e-16}\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/17zuoye/pyirt\n",
    "import pandas as pd\n",
    "from pyirt import irt\n",
    "\n",
    "data = []\n",
    "'''\n",
    "with open(\"/data/fjsdata/ctKngBase/kb.csv\", 'r') as f:\n",
    "    line_num = 0\n",
    "    for line in f:\n",
    "        line_num += 1\n",
    "        if (line_num != 1):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            uid, qid, ans = line.strip().split('|')\n",
    "            if (int(ans)>3):\n",
    "                data.append([int(uid), int(qid), 1])\n",
    "            else :data.append([int(uid), int(qid), 0])\n",
    "print (data[0:5])\n",
    "'''\n",
    "data =[[1,1,1],[1,2,0],[2,1,0],[2,2,1]]\n",
    "item_param, user_param = irt(data, max_iter=2)\n",
    "print (item_param)\n",
    "print (user_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

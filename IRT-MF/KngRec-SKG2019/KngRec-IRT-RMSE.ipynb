{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is:2547452 rows and 3 columns\n",
      "Number of 0:\n",
      "0.00000000    94453\n",
      "0.00000001     4162\n",
      "0.00000002     2091\n",
      "0.00000003     1447\n",
      "0.00000004     1057\n",
      "0.06582965     1047\n",
      "0.00000005      918\n",
      "0.16498579      776\n",
      "0.15383277      744\n",
      "0.00000006      721\n",
      "0.13034388      670\n",
      "0.11983165      663\n",
      "0.00000007      654\n",
      "0.16067967      612\n",
      "0.12443317      583\n",
      "0.14342331      582\n",
      "0.00000008      576\n",
      "0.00000009      505\n",
      "0.00000010      499\n",
      "0.00000011      439\n",
      "0.10575668      432\n",
      "0.16019196      405\n",
      "0.00000012      398\n",
      "0.17554315      395\n",
      "0.19255729      394\n",
      "0.00000013      380\n",
      "0.15427646      376\n",
      "0.12000412      370\n",
      "0.14850679      367\n",
      "0.15242517      366\n",
      "              ...  \n",
      "0.22198899        1\n",
      "0.15051099        1\n",
      "0.06069347        1\n",
      "0.01952361        1\n",
      "0.05275973        1\n",
      "0.11683059        1\n",
      "0.11746221        1\n",
      "0.07722803        1\n",
      "0.09594550        1\n",
      "0.10126178        1\n",
      "0.05624077        1\n",
      "0.04826663        1\n",
      "0.08494356        1\n",
      "0.01645989        1\n",
      "0.05035707        1\n",
      "0.07638198        1\n",
      "0.00592972        1\n",
      "0.00900640        1\n",
      "0.08617737        1\n",
      "0.05147617        1\n",
      "0.07800194        1\n",
      "0.06121785        1\n",
      "0.19291044        1\n",
      "0.07369757        1\n",
      "0.15033000        1\n",
      "0.05144945        1\n",
      "0.05912079        1\n",
      "0.04929917        1\n",
      "0.09275664        1\n",
      "0.06279668        1\n",
      "Name: irt, Length: 1919048, dtype: int64\n",
      "(0, 4)\n"
     ]
    }
   ],
   "source": [
    "import surprise as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)\n",
    "kbdata = kbdata.loc[(kbdata['num']<200)]#seven months, one per day\n",
    "print ('Dataset shape is:%d rows and %d columns'%(kbdata.shape[0],kbdata.shape[1]))\n",
    "\n",
    "#2.Calculating the mean of CSRs and KEs.\n",
    "Ab_csr = kbdata['num'].groupby(kbdata['csr']).mean()#the type of groupby is Series\n",
    "Di_ke = kbdata['num'].groupby(kbdata['ke']).mean()\n",
    "#3.Calculating the IRT of every pair<csr,ke> which is the pdf of norm\n",
    "#mu=Di_ke,sigma=Ab_csr\n",
    "#x[2]=num,x[1]=ke,x[0]=csr\n",
    "kbdata['irt'] = kbdata.apply(lambda x: \"{:.8f}\".format(stats.norm.pdf(int(x[2]), Di_ke[int(x[1])], Ab_csr[int(x[0])])),axis=1)\n",
    "#kbdata['irt'] = kbdata['irt'].apply(lambda x: 1 if float(x)>0 else 0)\n",
    "print ('Number of 0:')\n",
    "print (kbdata['irt'].value_counts())\n",
    "print (kbdata[kbdata['irt']==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0586\n",
      "0.058622259565876765\n"
     ]
    }
   ],
   "source": [
    "#NMF,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.NMF()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by RMSE\n",
    "print (sp.accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0334\n",
      "0.033445300632199186\n"
     ]
    }
   ],
   "source": [
    "#SVD,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.SVD()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by RMSE\n",
    "print (sp.accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0586\n",
      "0.05861593588371108\n"
     ]
    }
   ],
   "source": [
    "#NMF,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.NMF()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by RMSE\n",
    "print (sp.accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10216\n",
      "96324\n",
      "984045984\n",
      "2547452\n",
      "dataset density:0.002493\n"
     ]
    }
   ],
   "source": [
    "NUM_USERS = kbdata['csr'].max() + 1\n",
    "NUM_ITEMS = kbdata['ke'].max() + 1\n",
    "print (NUM_USERS)\n",
    "print (NUM_ITEMS)\n",
    "print (NUM_USERS*NUM_ITEMS)\n",
    "print (len(kbdata))\n",
    "print('dataset density:{:f}'.format((len(kbdata)-94453)*1.0/(NUM_USERS*NUM_ITEMS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is:2547452 rows and 3 columns\n",
      "RMSE: 0.0605\n",
      "0.06050782172230934\n"
     ]
    }
   ],
   "source": [
    "import surprise as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)\n",
    "kbdata = kbdata.loc[(kbdata['num']<200)]#seven months, one per day\n",
    "print ('Dataset shape is:%d rows and %d columns'%(kbdata.shape[0],kbdata.shape[1]))\n",
    "\n",
    "#2.Calculating the mean of CSRs and KEs.\n",
    "Ab_csr = kbdata['num'].groupby(kbdata['csr']).mean()#the type of groupby is Series\n",
    "Di_ke = kbdata['num'].groupby(kbdata['ke']).mean()\n",
    "#3.Calculating the IRT of every pair<csr,ke> which is the pdf of norm\n",
    "#mu=Di_ke,sigma=Ab_csr\n",
    "#x[2]=num,x[1]=ke,x[0]=csr\n",
    "kbdata['irt'] = kbdata.apply(lambda x: \"{:.8f}\".format(stats.norm.pdf(int(x[2]), Di_ke[int(x[1])], Ab_csr[int(x[0])])),axis=1)\n",
    "\n",
    "#SVD,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.SVD(n_factors=20,lr_all=3e-5,reg_all=0.02)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by RMSE\n",
    "print (sp.accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is:2547452 rows and 3 columns\n",
      "RMSE: 0.0749\n",
      "0.07489168018822281\n"
     ]
    }
   ],
   "source": [
    "import surprise as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)\n",
    "kbdata = kbdata.loc[(kbdata['num']<200)]#seven months, one per day\n",
    "print ('Dataset shape is:%d rows and %d columns'%(kbdata.shape[0],kbdata.shape[1]))\n",
    "\n",
    "#2.Calculating the mean of CSRs and KEs.\n",
    "Ab_csr = kbdata['num'].groupby(kbdata['csr']).mean()#the type of groupby is Series\n",
    "Di_ke = kbdata['num'].groupby(kbdata['ke']).mean()\n",
    "#3.Calculating the IRT of every pair<csr,ke> which is the pdf of norm\n",
    "#mu=Di_ke,sigma=Ab_csr\n",
    "#x[2]=num,x[1]=ke,x[0]=csr\n",
    "kbdata['irt'] = kbdata.apply(lambda x: \"{:.8f}\".format(stats.norm.pdf(int(x[2]), Di_ke[int(x[1])], Ab_csr[int(x[0])])),axis=1)\n",
    "\n",
    "#SVD,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.SVD(n_factors=50,lr_all=3e-5,reg_all=0.02)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by RMSE\n",
    "print (sp.accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is:2547452 rows and 3 columns\n",
      "RMSE: 0.1153\n",
      "0.11531762201920222\n"
     ]
    }
   ],
   "source": [
    "import surprise as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)\n",
    "kbdata = kbdata.loc[(kbdata['num']<200)]#seven months, one per day\n",
    "print ('Dataset shape is:%d rows and %d columns'%(kbdata.shape[0],kbdata.shape[1]))\n",
    "\n",
    "#2.Calculating the mean of CSRs and KEs.\n",
    "Ab_csr = kbdata['num'].groupby(kbdata['csr']).mean()#the type of groupby is Series\n",
    "Di_ke = kbdata['num'].groupby(kbdata['ke']).mean()\n",
    "#3.Calculating the IRT of every pair<csr,ke> which is the pdf of norm\n",
    "#mu=Di_ke,sigma=Ab_csr\n",
    "#x[2]=num,x[1]=ke,x[0]=csr\n",
    "kbdata['irt'] = kbdata.apply(lambda x: \"{:.8f}\".format(stats.norm.pdf(int(x[2]), Di_ke[int(x[1])], Ab_csr[int(x[0])])),axis=1)\n",
    "\n",
    "#SVD,threshold=0.1\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "algo = sp.SVD(n_factors=200,lr_all=3e-5,reg_all=0.02)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "#4.measuring the performance of SVD by RMSE\n",
    "print (sp.accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is:2547452 rows and 3 columns\n",
      "  K                RMSE\n",
      "RMSE: 0.0315\n",
      " 50          0.03152883\n",
      "RMSE: 0.0334\n",
      "100          0.03338732\n",
      "RMSE: 0.0354\n",
      "200          0.03541587\n",
      "RMSE: 0.0351\n",
      "500          0.03508189\n"
     ]
    }
   ],
   "source": [
    "import surprise as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "#1.Loading the dataset and Excluding the outliers\n",
    "kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kb.csv\", sep='|', low_memory=False)\n",
    "#seven month multiply thirty days per month is equal to 210,and one time per day multiply 210 is 210.\n",
    "kbdata = kbdata.loc[(kbdata['num']<200)]\n",
    "print ('Dataset shape is:%d rows and %d columns'%(kbdata.shape[0],kbdata.shape[1]))\n",
    "\n",
    "#2.Calculating the mean of CSRs and KEs.\n",
    "Ab_csr = kbdata['num'].groupby(kbdata['csr']).mean()#the type of groupby is Series\n",
    "Di_ke = kbdata['num'].groupby(kbdata['ke']).mean()\n",
    "#3.Calculating the IRT of every pair<csr,ke> which is the pdf of norm\n",
    "#mu=Di_ke,sigma=Ab_csr\n",
    "#x[2]=num,x[1]=ke,x[0]=csr\n",
    "kbdata['irt'] = kbdata.apply(lambda x: \"{:.8f}\".format(stats.norm.pdf(int(x[2]), Di_ke[int(x[1])], Ab_csr[int(x[0])])),axis=1)\n",
    "#2.Transforming into data format of surprise and spliting the train-set and test-set\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "reader = sp.Reader(rating_scale=(0, 1))\n",
    "spdata = sp.Dataset.load_from_df(kbdata[['csr', 'ke', 'irt']],reader)\n",
    "# sampling random trainset and testset, and test set is made of 10% of the ratings.\n",
    "#trainset, testset = sp.model_selection.train_test_split(spdata, test_size=.1)\n",
    "trainset = spdata.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "#3.Training the model and predicting ratings for the testset\n",
    "print (\"%3s%20s\" % ('K','RMSE'))\n",
    "for k in [50,100,200,500]:\n",
    "    #3.Training the model and predicting ratings for the testset\n",
    "    algo = sp.SVD(n_factors=k)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)#testset include positive and negtive sample.\n",
    "\n",
    "    #4.rating prediction\n",
    "    RMSE = sp.accuracy.rmse(predictions)\n",
    "    print (\"%3s%20.8f\" % (k, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
